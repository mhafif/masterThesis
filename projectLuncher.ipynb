{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"projectLuncher.ipynb","provenance":[],"collapsed_sections":["hGn4F3E5g0tF","Tw1AUxGfhhvz","L6eYrQVmhmiB","25i-JvoKg0Z-","I7KhrHvChuwF","Y3IhXzf8hzjE","cY9GpPa5h0rF","Qe8gwVzH_X3t","wKZWxUwOgyF8","CJI59-TV_i4v","rOzvIENf_kdK","J42kbaUj26um"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yqg1EP2tgMke","colab_type":"text"},"source":["# Google Colab settings and importation"]},{"cell_type":"code","metadata":{"id":"-Ha7nSrWGW6j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596929855614,"user_tz":-120,"elapsed":8468,"user":{"displayName":"Mounir Hafif","photoUrl":"","userId":"06014250052201432275"}},"outputId":"7efd2e3f-2005-43a2-b5a8-ea5fa8466317"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ijwH7hUrjsyQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596737733881,"user_tz":-120,"elapsed":827,"user":{"displayName":"Mounir Hafif","photoUrl":"","userId":"06014250052201432275"}},"outputId":"7697c0e5-be85-45b1-a33d-de50a14e8c0a"},"source":["# when intending to train either GAN or VAE\n","%tensorflow_version 1.x\n","\n","# when intending to train VAEGAN\n","#%tensorflow_version 2.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V2TFEUDYUkBs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596737741753,"user_tz":-120,"elapsed":5856,"user":{"displayName":"Mounir Hafif","photoUrl":"","userId":"06014250052201432275"}},"outputId":"e08214fa-fca8-4735-98d8-975728328fbd"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E_lMVNpoSmD4","colab_type":"code","colab":{}},"source":["!rm -rf \"/content/celeba48.zip\"\n","!cp \"/content/drive/My Drive/Thesis/Data/celeba48.zip\" \"/content\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hGn4F3E5g0tF","colab_type":"text"},"source":["# MODELS SAMPLING"]},{"cell_type":"markdown","metadata":{"id":"Tw1AUxGfhhvz","colab_type":"text"},"source":["## VAE"]},{"cell_type":"code","metadata":{"id":"AHa1yuh-hHCw","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE/VAE_MNIST.py\" -sample weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSgq5gDIhHii","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE/VAE_CELEBA.py\" -sample weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JnsGSGL1hjje","colab_type":"text"},"source":["## GAN"]},{"cell_type":"code","metadata":{"id":"_hWsrIYWhLCD","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/GAN/GAN_MNIST.py\" -sample weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S590qHlxhL6K","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/GAN/GAN_CELEBA.py\" -sample weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6eYrQVmhmiB","colab_type":"text"},"source":["## VAE-GAN"]},{"cell_type":"code","metadata":{"id":"ajl8zZ7ghOFz","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE-GAN/VAE_GAN_MNIST.py\" -sample weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aNp-y8O5hQEV","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE-GAN/VAE_GAN_CELEBA.py\" -sample weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"25i-JvoKg0Z-","colab_type":"text"},"source":["# MODELS PLOTTING"]},{"cell_type":"markdown","metadata":{"id":"I7KhrHvChuwF","colab_type":"text"},"source":["## VAE"]},{"cell_type":"code","metadata":{"id":"hgNt0KGyhu3_","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE/VAE_MNIST.py\" -plot weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ltOiqwHhvSg","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE/VAE_CELEBA.py\" -plot weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3IhXzf8hzjE","colab_type":"text"},"source":["## GAN"]},{"cell_type":"code","metadata":{"id":"JkgvpWR3hu6Q","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/GAN/GAN_MNIST.py\" -plot weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFWK2Lzmh0Xj","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/GAN/GAN_CELEBA.py\" -plot weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cY9GpPa5h0rF","colab_type":"text"},"source":["## VAE-GAN"]},{"cell_type":"code","metadata":{"id":"8qIbT4KZh1Bn","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE-GAN/VAE_GAN_MNIST.py\" -plot weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGIZ5wvFh1TI","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE-GAN/VAE_GAN_CELEBA.py\" -plot weights.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qe8gwVzH_X3t","colab_type":"text"},"source":["# MODELS TRAINING"]},{"cell_type":"markdown","metadata":{"id":"wKZWxUwOgyF8","colab_type":"text"},"source":["## VAE"]},{"cell_type":"code","metadata":{"id":"lo-Zem-kr2RP","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE/VAE_MNIST.py\" -train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cleOzgiIS1pB","colab_type":"text"},"source":["```\n","2020-08-01 14:05:53.320544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-08-01 14:05:53.509971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","epoch: 1, [TrainSet loss: 187.997, TrainSet accuracy: 0.793] [ValidSet loss: 247.872, ValidSet accuracy: 0.816] \n","epoch: 2, [TrainSet loss: 137.838, TrainSet accuracy: 0.803] [ValidSet loss: 178.596, ValidSet accuracy: 0.816] \n","epoch: 3, [TrainSet loss: 129.881, TrainSet accuracy: 0.806] [ValidSet loss: 131.378, ValidSet accuracy: 0.816] \n","epoch: 4, [TrainSet loss: 124.375, TrainSet accuracy: 0.807] [ValidSet loss: 120.827, ValidSet accuracy: 0.815] \n","epoch: 5, [TrainSet loss: 120.168, TrainSet accuracy: 0.808] [ValidSet loss: 116.683, ValidSet accuracy: 0.817] \n","epoch: 6, [TrainSet loss: 116.535, TrainSet accuracy: 0.809] [ValidSet loss: 113.713, ValidSet accuracy: 0.817] \n","epoch: 7, [TrainSet loss: 113.750, TrainSet accuracy: 0.809] [ValidSet loss: 111.476, ValidSet accuracy: 0.817] \n","epoch: 8, [TrainSet loss: 111.668, TrainSet accuracy: 0.810] [ValidSet loss: 109.401, ValidSet accuracy: 0.817] \n","epoch: 9, [TrainSet loss: 110.420, TrainSet accuracy: 0.810] [ValidSet loss: 110.789, ValidSet accuracy: 0.816] \n","epoch: 10, [TrainSet loss: 108.940, TrainSet accuracy: 0.810] [ValidSet loss: 106.522, ValidSet accuracy: 0.818] \n","epoch: 11, [TrainSet loss: 107.785, TrainSet accuracy: 0.811] [ValidSet loss: 105.795, ValidSet accuracy: 0.819] \n","epoch: 12, [TrainSet loss: 106.996, TrainSet accuracy: 0.811] [ValidSet loss: 105.438, ValidSet accuracy: 0.819] \n","epoch: 13, [TrainSet loss: 106.142, TrainSet accuracy: 0.811] [ValidSet loss: 104.427, ValidSet accuracy: 0.819] \n","epoch: 14, [TrainSet loss: 105.593, TrainSet accuracy: 0.811] [ValidSet loss: 104.199, ValidSet accuracy: 0.819] \n","epoch: 15, [TrainSet loss: 105.218, TrainSet accuracy: 0.811] [ValidSet loss: 104.218, ValidSet accuracy: 0.819] \n","epoch: 16, [TrainSet loss: 104.640, TrainSet accuracy: 0.811] [ValidSet loss: 102.697, ValidSet accuracy: 0.819] \n","epoch: 17, [TrainSet loss: 104.331, TrainSet accuracy: 0.811] [ValidSet loss: 103.944, ValidSet accuracy: 0.819] \n","epoch: 18, [TrainSet loss: 103.747, TrainSet accuracy: 0.812] [ValidSet loss: 102.489, ValidSet accuracy: 0.820] \n","epoch: 19, [TrainSet loss: 103.309, TrainSet accuracy: 0.812] [ValidSet loss: 102.252, ValidSet accuracy: 0.820] \n","epoch: 20, [TrainSet loss: 102.967, TrainSet accuracy: 0.812] [ValidSet loss: 101.766, ValidSet accuracy: 0.820] \n","epoch: 21, [TrainSet loss: 102.689, TrainSet accuracy: 0.812] [ValidSet loss: 101.553, ValidSet accuracy: 0.819] \n","epoch: 22, [TrainSet loss: 102.339, TrainSet accuracy: 0.812] [ValidSet loss: 101.583, ValidSet accuracy: 0.820] \n","epoch: 23, [TrainSet loss: 102.424, TrainSet accuracy: 0.812] [ValidSet loss: 101.209, ValidSet accuracy: 0.820] \n","epoch: 24, [TrainSet loss: 102.166, TrainSet accuracy: 0.812] [ValidSet loss: 101.799, ValidSet accuracy: 0.820] \n","epoch: 25, [TrainSet loss: 102.026, TrainSet accuracy: 0.812] [ValidSet loss: 101.177, ValidSet accuracy: 0.819] \n","epoch: 26, [TrainSet loss: 101.649, TrainSet accuracy: 0.812] [ValidSet loss: 101.036, ValidSet accuracy: 0.820] \n","epoch: 27, [TrainSet loss: 101.407, TrainSet accuracy: 0.812] [ValidSet loss: 101.635, ValidSet accuracy: 0.819] \n","epoch: 28, [TrainSet loss: 101.312, TrainSet accuracy: 0.812] [ValidSet loss: 101.636, ValidSet accuracy: 0.820] \n","epoch: 29, [TrainSet loss: 101.311, TrainSet accuracy: 0.812] [ValidSet loss: 101.002, ValidSet accuracy: 0.819] \n","epoch: 30, [TrainSet loss: 100.939, TrainSet accuracy: 0.812] [ValidSet loss: 101.591, ValidSet accuracy: 0.820] \n","epoch: 31, [TrainSet loss: 100.562, TrainSet accuracy: 0.812] [ValidSet loss: 100.686, ValidSet accuracy: 0.819] \n","epoch: 32, [TrainSet loss: 100.671, TrainSet accuracy: 0.812] [ValidSet loss: 100.677, ValidSet accuracy: 0.819] \n","epoch: 33, [TrainSet loss: 100.282, TrainSet accuracy: 0.812] [ValidSet loss: 99.944, ValidSet accuracy: 0.820] \n","epoch: 34, [TrainSet loss: 100.522, TrainSet accuracy: 0.812] [ValidSet loss: 100.299, ValidSet accuracy: 0.820] \n","epoch: 35, [TrainSet loss: 100.260, TrainSet accuracy: 0.812] [ValidSet loss: 100.547, ValidSet accuracy: 0.820] \n","epoch: 36, [TrainSet loss: 100.335, TrainSet accuracy: 0.812] [ValidSet loss: 99.765, ValidSet accuracy: 0.820] \n","epoch: 37, [TrainSet loss: 100.078, TrainSet accuracy: 0.812] [ValidSet loss: 99.854, ValidSet accuracy: 0.820] \n","epoch: 38, [TrainSet loss: 99.833, TrainSet accuracy: 0.812] [ValidSet loss: 100.623, ValidSet accuracy: 0.820] \n","epoch: 39, [TrainSet loss: 99.801, TrainSet accuracy: 0.812] [ValidSet loss: 100.373, ValidSet accuracy: 0.819] \n","epoch: 40, [TrainSet loss: 99.379, TrainSet accuracy: 0.812] [ValidSet loss: 99.468, ValidSet accuracy: 0.820] \n","epoch: 41, [TrainSet loss: 99.682, TrainSet accuracy: 0.812] [ValidSet loss: 100.776, ValidSet accuracy: 0.819] \n","epoch: 42, [TrainSet loss: 99.466, TrainSet accuracy: 0.812] [ValidSet loss: 99.635, ValidSet accuracy: 0.820] \n","epoch: 43, [TrainSet loss: 99.410, TrainSet accuracy: 0.812] [ValidSet loss: 100.126, ValidSet accuracy: 0.820] \n","epoch: 44, [TrainSet loss: 99.140, TrainSet accuracy: 0.812] [ValidSet loss: 99.461, ValidSet accuracy: 0.820] \n","epoch: 45, [TrainSet loss: 98.952, TrainSet accuracy: 0.812] [ValidSet loss: 99.406, ValidSet accuracy: 0.820] \n","epoch: 46, [TrainSet loss: 98.957, TrainSet accuracy: 0.812] [ValidSet loss: 99.203, ValidSet accuracy: 0.820] \n","epoch: 47, [TrainSet loss: 98.802, TrainSet accuracy: 0.812] [ValidSet loss: 99.505, ValidSet accuracy: 0.820] \n","epoch: 48, [TrainSet loss: 98.903, TrainSet accuracy: 0.812] [ValidSet loss: 99.475, ValidSet accuracy: 0.820] \n","epoch: 49, [TrainSet loss: 98.658, TrainSet accuracy: 0.812] [ValidSet loss: 99.641, ValidSet accuracy: 0.820] \n","epoch: 50, [TrainSet loss: 98.763, TrainSet accuracy: 0.812] [ValidSet loss: 99.150, ValidSet accuracy: 0.820] \n","epoch: 51, [TrainSet loss: 98.763, TrainSet accuracy: 0.812] [ValidSet loss: 99.475, ValidSet accuracy: 0.820] \n","epoch: 52, [TrainSet loss: 98.501, TrainSet accuracy: 0.812] [ValidSet loss: 99.527, ValidSet accuracy: 0.820] \n","epoch: 53, [TrainSet loss: 98.513, TrainSet accuracy: 0.812] [ValidSet loss: 99.173, ValidSet accuracy: 0.820] \n","epoch: 54, [TrainSet loss: 98.295, TrainSet accuracy: 0.812] [ValidSet loss: 99.548, ValidSet accuracy: 0.820] \n","epoch: 55, [TrainSet loss: 98.211, TrainSet accuracy: 0.812] [ValidSet loss: 99.734, ValidSet accuracy: 0.820] \n","epoch: 56, [TrainSet loss: 98.134, TrainSet accuracy: 0.813] [ValidSet loss: 98.948, ValidSet accuracy: 0.820] \n","epoch: 57, [TrainSet loss: 98.335, TrainSet accuracy: 0.812] [ValidSet loss: 99.282, ValidSet accuracy: 0.820] \n","epoch: 58, [TrainSet loss: 98.102, TrainSet accuracy: 0.812] [ValidSet loss: 99.881, ValidSet accuracy: 0.820] \n","epoch: 59, [TrainSet loss: 98.110, TrainSet accuracy: 0.813] [ValidSet loss: 99.328, ValidSet accuracy: 0.820] \n","epoch: 60, [TrainSet loss: 97.887, TrainSet accuracy: 0.813] [ValidSet loss: 98.916, ValidSet accuracy: 0.820] \n","epoch: 61, [TrainSet loss: 98.015, TrainSet accuracy: 0.813] [ValidSet loss: 99.758, ValidSet accuracy: 0.820] \n","epoch: 62, [TrainSet loss: 97.763, TrainSet accuracy: 0.813] [ValidSet loss: 98.984, ValidSet accuracy: 0.820] \n","epoch: 63, [TrainSet loss: 97.855, TrainSet accuracy: 0.813] [ValidSet loss: 98.636, ValidSet accuracy: 0.820] \n","epoch: 64, [TrainSet loss: 97.775, TrainSet accuracy: 0.813] [ValidSet loss: 98.900, ValidSet accuracy: 0.820] \n","epoch: 65, [TrainSet loss: 97.755, TrainSet accuracy: 0.813] [ValidSet loss: 99.024, ValidSet accuracy: 0.820] \n","epoch: 66, [TrainSet loss: 97.668, TrainSet accuracy: 0.813] [ValidSet loss: 99.488, ValidSet accuracy: 0.820] \n","epoch: 67, [TrainSet loss: 97.653, TrainSet accuracy: 0.813] [ValidSet loss: 99.035, ValidSet accuracy: 0.820] \n","epoch: 68, [TrainSet loss: 97.630, TrainSet accuracy: 0.813] [ValidSet loss: 99.456, ValidSet accuracy: 0.820] \n","epoch: 69, [TrainSet loss: 97.334, TrainSet accuracy: 0.813] [ValidSet loss: 99.000, ValidSet accuracy: 0.820] \n","epoch: 70, [TrainSet loss: 97.380, TrainSet accuracy: 0.813] [ValidSet loss: 99.293, ValidSet accuracy: 0.820] \n","epoch: 71, [TrainSet loss: 97.450, TrainSet accuracy: 0.813] [ValidSet loss: 98.654, ValidSet accuracy: 0.820] \n","epoch: 72, [TrainSet loss: 97.442, TrainSet accuracy: 0.813] [ValidSet loss: 98.620, ValidSet accuracy: 0.820] \n","epoch: 73, [TrainSet loss: 97.082, TrainSet accuracy: 0.813] [ValidSet loss: 99.034, ValidSet accuracy: 0.820] \n","epoch: 74, [TrainSet loss: 97.087, TrainSet accuracy: 0.813] [ValidSet loss: 98.761, ValidSet accuracy: 0.820] \n","epoch: 75, [TrainSet loss: 97.178, TrainSet accuracy: 0.813] [ValidSet loss: 98.729, ValidSet accuracy: 0.820] \n","epoch: 76, [TrainSet loss: 96.914, TrainSet accuracy: 0.813] [ValidSet loss: 98.779, ValidSet accuracy: 0.820] \n","epoch: 77, [TrainSet loss: 97.128, TrainSet accuracy: 0.813] [ValidSet loss: 99.026, ValidSet accuracy: 0.820] \n","epoch: 78, [TrainSet loss: 96.988, TrainSet accuracy: 0.813] [ValidSet loss: 99.141, ValidSet accuracy: 0.820] \n","epoch: 79, [TrainSet loss: 97.039, TrainSet accuracy: 0.813] [ValidSet loss: 98.607, ValidSet accuracy: 0.820] \n","epoch: 80, [TrainSet loss: 96.895, TrainSet accuracy: 0.813] [ValidSet loss: 98.682, ValidSet accuracy: 0.820] \n","epoch: 81, [TrainSet loss: 96.917, TrainSet accuracy: 0.813] [ValidSet loss: 99.031, ValidSet accuracy: 0.820] \n","epoch: 82, [TrainSet loss: 96.763, TrainSet accuracy: 0.813] [ValidSet loss: 98.787, ValidSet accuracy: 0.820] \n","epoch: 83, [TrainSet loss: 96.762, TrainSet accuracy: 0.813] [ValidSet loss: 99.427, ValidSet accuracy: 0.820] \n","epoch: 84, [TrainSet loss: 96.655, TrainSet accuracy: 0.813] [ValidSet loss: 99.337, ValidSet accuracy: 0.821] \n","epoch: 85, [TrainSet loss: 96.714, TrainSet accuracy: 0.813] [ValidSet loss: 98.855, ValidSet accuracy: 0.820] \n","epoch: 86, [TrainSet loss: 96.744, TrainSet accuracy: 0.813] [ValidSet loss: 98.636, ValidSet accuracy: 0.820] \n","epoch: 87, [TrainSet loss: 96.907, TrainSet accuracy: 0.813] [ValidSet loss: 98.590, ValidSet accuracy: 0.820] \n","epoch: 88, [TrainSet loss: 96.508, TrainSet accuracy: 0.813] [ValidSet loss: 98.900, ValidSet accuracy: 0.820] \n","epoch: 89, [TrainSet loss: 96.566, TrainSet accuracy: 0.813] [ValidSet loss: 98.613, ValidSet accuracy: 0.820] \n","epoch: 90, [TrainSet loss: 96.762, TrainSet accuracy: 0.813] [ValidSet loss: 98.923, ValidSet accuracy: 0.820] \n","epoch: 91, [TrainSet loss: 96.558, TrainSet accuracy: 0.813] [ValidSet loss: 99.230, ValidSet accuracy: 0.820] \n","epoch: 92, [TrainSet loss: 96.442, TrainSet accuracy: 0.813] [ValidSet loss: 99.347, ValidSet accuracy: 0.820] \n","epoch: 93, [TrainSet loss: 96.433, TrainSet accuracy: 0.813] [ValidSet loss: 99.564, ValidSet accuracy: 0.820] \n","epoch: 94, [TrainSet loss: 96.404, TrainSet accuracy: 0.813] [ValidSet loss: 99.007, ValidSet accuracy: 0.820] \n","epoch: 95, [TrainSet loss: 96.398, TrainSet accuracy: 0.813] [ValidSet loss: 98.717, ValidSet accuracy: 0.820] \n","epoch: 96, [TrainSet loss: 96.377, TrainSet accuracy: 0.813] [ValidSet loss: 98.488, ValidSet accuracy: 0.820] \n","epoch: 97, [TrainSet loss: 96.285, TrainSet accuracy: 0.813] [ValidSet loss: 98.542, ValidSet accuracy: 0.820] \n","epoch: 98, [TrainSet loss: 96.200, TrainSet accuracy: 0.813] [ValidSet loss: 99.956, ValidSet accuracy: 0.820] \n","epoch: 99, [TrainSet loss: 96.273, TrainSet accuracy: 0.813] [ValidSet loss: 98.671, ValidSet accuracy: 0.820] \n","epoch: 100, [TrainSet loss: 96.128, TrainSet accuracy: 0.813] [ValidSet loss: 98.551, ValidSet accuracy: 0.820] \n","14:27:49\n","```"]},{"cell_type":"code","metadata":{"id":"VhblFSMQ5qKT","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE/VAE_CELEBA.py\" -train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CiTXNUF5Tlgh","colab_type":"text"},"source":["```\n","2020-08-01 14:35:03.381617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-08-01 14:35:03.568671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","epoch: 1, [TrainSet loss: 1377.259, TrainSet accuracy: 0.798] [ValidSet loss: 1481.872, ValidSet accuracy: 0.816] \n","epoch: 2, [TrainSet loss: 1313.076, TrainSet accuracy: 0.812] [ValidSet loss: 1324.766, ValidSet accuracy: 0.820] \n","epoch: 3, [TrainSet loss: 1296.249, TrainSet accuracy: 0.818] [ValidSet loss: 1306.290, ValidSet accuracy: 0.830] \n","epoch: 4, [TrainSet loss: 1287.767, TrainSet accuracy: 0.827] [ValidSet loss: 1299.089, ValidSet accuracy: 0.822] \n","epoch: 5, [TrainSet loss: 1281.733, TrainSet accuracy: 0.831] [ValidSet loss: 1315.824, ValidSet accuracy: 0.827] \n","epoch: 6, [TrainSet loss: 1278.625, TrainSet accuracy: 0.833] [ValidSet loss: 1301.820, ValidSet accuracy: 0.835] \n","epoch: 7, [TrainSet loss: 1276.478, TrainSet accuracy: 0.835] [ValidSet loss: 1338.293, ValidSet accuracy: 0.825] \n","epoch: 8, [TrainSet loss: 1274.036, TrainSet accuracy: 0.837] [ValidSet loss: 1291.345, ValidSet accuracy: 0.844] \n","epoch: 9, [TrainSet loss: 1272.520, TrainSet accuracy: 0.838] [ValidSet loss: 1271.841, ValidSet accuracy: 0.842] \n","epoch: 10, [TrainSet loss: 1271.481, TrainSet accuracy: 0.840] [ValidSet loss: 1275.445, ValidSet accuracy: 0.832] \n","epoch: 11, [TrainSet loss: 1270.194, TrainSet accuracy: 0.840] [ValidSet loss: 1277.421, ValidSet accuracy: 0.840] \n","epoch: 12, [TrainSet loss: 1269.600, TrainSet accuracy: 0.841] [ValidSet loss: 1274.826, ValidSet accuracy: 0.829] \n","epoch: 13, [TrainSet loss: 1268.354, TrainSet accuracy: 0.841] [ValidSet loss: 1269.667, ValidSet accuracy: 0.834] \n","epoch: 14, [TrainSet loss: 1267.749, TrainSet accuracy: 0.841] [ValidSet loss: 1272.457, ValidSet accuracy: 0.839] \n","epoch: 15, [TrainSet loss: 1266.607, TrainSet accuracy: 0.843] [ValidSet loss: 1271.426, ValidSet accuracy: 0.843] \n","epoch: 16, [TrainSet loss: 1266.136, TrainSet accuracy: 0.842] [ValidSet loss: 1267.745, ValidSet accuracy: 0.836] \n","epoch: 17, [TrainSet loss: 1265.898, TrainSet accuracy: 0.843] [ValidSet loss: 1267.576, ValidSet accuracy: 0.848] \n","epoch: 18, [TrainSet loss: 1265.600, TrainSet accuracy: 0.843] [ValidSet loss: 1270.446, ValidSet accuracy: 0.834] \n","epoch: 19, [TrainSet loss: 1264.510, TrainSet accuracy: 0.843] [ValidSet loss: 1268.472, ValidSet accuracy: 0.845] \n","epoch: 20, [TrainSet loss: 1264.235, TrainSet accuracy: 0.844] [ValidSet loss: 1268.614, ValidSet accuracy: 0.843] \n","epoch: 21, [TrainSet loss: 1263.967, TrainSet accuracy: 0.844] [ValidSet loss: 1265.133, ValidSet accuracy: 0.846] \n","epoch: 22, [TrainSet loss: 1263.296, TrainSet accuracy: 0.845] [ValidSet loss: 1266.451, ValidSet accuracy: 0.847] \n","epoch: 23, [TrainSet loss: 1262.737, TrainSet accuracy: 0.844] [ValidSet loss: 1263.404, ValidSet accuracy: 0.845] \n","epoch: 24, [TrainSet loss: 1262.494, TrainSet accuracy: 0.844] [ValidSet loss: 1266.746, ValidSet accuracy: 0.846] \n","epoch: 25, [TrainSet loss: 1262.553, TrainSet accuracy: 0.845] [ValidSet loss: 1262.606, ValidSet accuracy: 0.848] \n","epoch: 26, [TrainSet loss: 1261.886, TrainSet accuracy: 0.845] [ValidSet loss: 1262.800, ValidSet accuracy: 0.838] \n","epoch: 27, [TrainSet loss: 1261.764, TrainSet accuracy: 0.845] [ValidSet loss: 1264.230, ValidSet accuracy: 0.847] \n","epoch: 28, [TrainSet loss: 1261.478, TrainSet accuracy: 0.846] [ValidSet loss: 1263.528, ValidSet accuracy: 0.846] \n","epoch: 29, [TrainSet loss: 1261.117, TrainSet accuracy: 0.846] [ValidSet loss: 1261.003, ValidSet accuracy: 0.849] \n","epoch: 30, [TrainSet loss: 1260.717, TrainSet accuracy: 0.846] [ValidSet loss: 1261.942, ValidSet accuracy: 0.847] \n","epoch: 31, [TrainSet loss: 1260.675, TrainSet accuracy: 0.846] [ValidSet loss: 1262.056, ValidSet accuracy: 0.850] \n","epoch: 32, [TrainSet loss: 1261.091, TrainSet accuracy: 0.846] [ValidSet loss: 1260.577, ValidSet accuracy: 0.848] \n","epoch: 33, [TrainSet loss: 1260.607, TrainSet accuracy: 0.846] [ValidSet loss: 1261.307, ValidSet accuracy: 0.848] \n","epoch: 34, [TrainSet loss: 1259.701, TrainSet accuracy: 0.846] [ValidSet loss: 1261.459, ValidSet accuracy: 0.847] \n","epoch: 35, [TrainSet loss: 1259.655, TrainSet accuracy: 0.846] [ValidSet loss: 1259.366, ValidSet accuracy: 0.850] \n","epoch: 36, [TrainSet loss: 1259.618, TrainSet accuracy: 0.847] [ValidSet loss: 1261.856, ValidSet accuracy: 0.848] \n","epoch: 37, [TrainSet loss: 1259.541, TrainSet accuracy: 0.847] [ValidSet loss: 1261.615, ValidSet accuracy: 0.851] \n","epoch: 38, [TrainSet loss: 1258.969, TrainSet accuracy: 0.848] [ValidSet loss: 1260.554, ValidSet accuracy: 0.847] \n","epoch: 39, [TrainSet loss: 1258.981, TrainSet accuracy: 0.847] [ValidSet loss: 1259.823, ValidSet accuracy: 0.841] \n","epoch: 40, [TrainSet loss: 1258.536, TrainSet accuracy: 0.847] [ValidSet loss: 1260.452, ValidSet accuracy: 0.845] \n","epoch: 41, [TrainSet loss: 1258.649, TrainSet accuracy: 0.848] [ValidSet loss: 1259.721, ValidSet accuracy: 0.849] \n","epoch: 42, [TrainSet loss: 1258.493, TrainSet accuracy: 0.848] [ValidSet loss: 1259.463, ValidSet accuracy: 0.849] \n","epoch: 43, [TrainSet loss: 1258.522, TrainSet accuracy: 0.848] [ValidSet loss: 1259.983, ValidSet accuracy: 0.850] \n","epoch: 44, [TrainSet loss: 1258.175, TrainSet accuracy: 0.847] [ValidSet loss: 1260.626, ValidSet accuracy: 0.850] \n","epoch: 45, [TrainSet loss: 1257.836, TrainSet accuracy: 0.848] [ValidSet loss: 1258.800, ValidSet accuracy: 0.844] \n","epoch: 46, [TrainSet loss: 1258.114, TrainSet accuracy: 0.848] [ValidSet loss: 1259.357, ValidSet accuracy: 0.851] \n","epoch: 47, [TrainSet loss: 1257.614, TrainSet accuracy: 0.848] [ValidSet loss: 1258.860, ValidSet accuracy: 0.844] \n","epoch: 48, [TrainSet loss: 1257.423, TrainSet accuracy: 0.848] [ValidSet loss: 1259.014, ValidSet accuracy: 0.847] \n","epoch: 49, [TrainSet loss: 1257.428, TrainSet accuracy: 0.848] [ValidSet loss: 1259.625, ValidSet accuracy: 0.842] \n","epoch: 50, [TrainSet loss: 1256.966, TrainSet accuracy: 0.848] [ValidSet loss: 1258.547, ValidSet accuracy: 0.844] \n","epoch: 51, [TrainSet loss: 1256.827, TrainSet accuracy: 0.848] [ValidSet loss: 1258.082, ValidSet accuracy: 0.849] \n","epoch: 52, [TrainSet loss: 1256.980, TrainSet accuracy: 0.848] [ValidSet loss: 1260.733, ValidSet accuracy: 0.851] \n","epoch: 53, [TrainSet loss: 1256.561, TrainSet accuracy: 0.848] [ValidSet loss: 1261.998, ValidSet accuracy: 0.852] \n","epoch: 54, [TrainSet loss: 1256.630, TrainSet accuracy: 0.848] [ValidSet loss: 1258.239, ValidSet accuracy: 0.852] \n","epoch: 55, [TrainSet loss: 1256.527, TrainSet accuracy: 0.849] [ValidSet loss: 1258.874, ValidSet accuracy: 0.850] \n","epoch: 56, [TrainSet loss: 1256.645, TrainSet accuracy: 0.849] [ValidSet loss: 1259.742, ValidSet accuracy: 0.850] \n","epoch: 57, [TrainSet loss: 1256.298, TrainSet accuracy: 0.849] [ValidSet loss: 1259.381, ValidSet accuracy: 0.850] \n","epoch: 58, [TrainSet loss: 1256.452, TrainSet accuracy: 0.849] [ValidSet loss: 1259.635, ValidSet accuracy: 0.846] \n","epoch: 59, [TrainSet loss: 1256.022, TrainSet accuracy: 0.849] [ValidSet loss: 1259.212, ValidSet accuracy: 0.850] \n","epoch: 60, [TrainSet loss: 1255.866, TrainSet accuracy: 0.849] [ValidSet loss: 1258.751, ValidSet accuracy: 0.851] \n","epoch: 61, [TrainSet loss: 1255.870, TrainSet accuracy: 0.849] [ValidSet loss: 1258.402, ValidSet accuracy: 0.849] \n","epoch: 62, [TrainSet loss: 1255.664, TrainSet accuracy: 0.848] [ValidSet loss: 1258.743, ValidSet accuracy: 0.847] \n","epoch: 63, [TrainSet loss: 1255.525, TrainSet accuracy: 0.849] [ValidSet loss: 1258.461, ValidSet accuracy: 0.851] \n","epoch: 64, [TrainSet loss: 1255.639, TrainSet accuracy: 0.849] [ValidSet loss: 1257.406, ValidSet accuracy: 0.849] \n","epoch: 65, [TrainSet loss: 1255.123, TrainSet accuracy: 0.849] [ValidSet loss: 1258.229, ValidSet accuracy: 0.853] \n","epoch: 66, [TrainSet loss: 1254.898, TrainSet accuracy: 0.849] [ValidSet loss: 1258.848, ValidSet accuracy: 0.849] \n","epoch: 67, [TrainSet loss: 1255.260, TrainSet accuracy: 0.849] [ValidSet loss: 1257.874, ValidSet accuracy: 0.852] \n","epoch: 68, [TrainSet loss: 1254.679, TrainSet accuracy: 0.849] [ValidSet loss: 1258.123, ValidSet accuracy: 0.849] \n","epoch: 69, [TrainSet loss: 1254.576, TrainSet accuracy: 0.849] [ValidSet loss: 1257.906, ValidSet accuracy: 0.850] \n","epoch: 70, [TrainSet loss: 1254.555, TrainSet accuracy: 0.849] [ValidSet loss: 1258.624, ValidSet accuracy: 0.849] \n","epoch: 71, [TrainSet loss: 1254.620, TrainSet accuracy: 0.850] [ValidSet loss: 1257.629, ValidSet accuracy: 0.847] \n","epoch: 72, [TrainSet loss: 1254.393, TrainSet accuracy: 0.849] [ValidSet loss: 1258.160, ValidSet accuracy: 0.852] \n","epoch: 73, [TrainSet loss: 1254.195, TrainSet accuracy: 0.849] [ValidSet loss: 1258.730, ValidSet accuracy: 0.851] \n","epoch: 74, [TrainSet loss: 1253.954, TrainSet accuracy: 0.849] [ValidSet loss: 1257.714, ValidSet accuracy: 0.849] \n","epoch: 75, [TrainSet loss: 1254.414, TrainSet accuracy: 0.849] [ValidSet loss: 1257.628, ValidSet accuracy: 0.850] \n","epoch: 76, [TrainSet loss: 1253.980, TrainSet accuracy: 0.849] [ValidSet loss: 1258.075, ValidSet accuracy: 0.851] \n","epoch: 77, [TrainSet loss: 1253.806, TrainSet accuracy: 0.850] [ValidSet loss: 1258.028, ValidSet accuracy: 0.850] \n","epoch: 78, [TrainSet loss: 1253.708, TrainSet accuracy: 0.849] [ValidSet loss: 1257.665, ValidSet accuracy: 0.850] \n","epoch: 79, [TrainSet loss: 1253.772, TrainSet accuracy: 0.850] [ValidSet loss: 1258.592, ValidSet accuracy: 0.849] \n","epoch: 80, [TrainSet loss: 1253.592, TrainSet accuracy: 0.849] [ValidSet loss: 1257.859, ValidSet accuracy: 0.850] \n","epoch: 81, [TrainSet loss: 1253.466, TrainSet accuracy: 0.850] [ValidSet loss: 1258.027, ValidSet accuracy: 0.849] \n","epoch: 82, [TrainSet loss: 1253.427, TrainSet accuracy: 0.850] [ValidSet loss: 1258.494, ValidSet accuracy: 0.847] \n","epoch: 83, [TrainSet loss: 1253.456, TrainSet accuracy: 0.850] [ValidSet loss: 1257.986, ValidSet accuracy: 0.854] \n","epoch: 84, [TrainSet loss: 1253.153, TrainSet accuracy: 0.850] [ValidSet loss: 1258.165, ValidSet accuracy: 0.852] \n","epoch: 85, [TrainSet loss: 1253.094, TrainSet accuracy: 0.850] [ValidSet loss: 1257.700, ValidSet accuracy: 0.847] \n","epoch: 86, [TrainSet loss: 1253.200, TrainSet accuracy: 0.850] [ValidSet loss: 1257.815, ValidSet accuracy: 0.852] \n","epoch: 87, [TrainSet loss: 1252.994, TrainSet accuracy: 0.849] [ValidSet loss: 1258.848, ValidSet accuracy: 0.850] \n","epoch: 88, [TrainSet loss: 1252.983, TrainSet accuracy: 0.850] [ValidSet loss: 1258.749, ValidSet accuracy: 0.844] \n","epoch: 89, [TrainSet loss: 1252.892, TrainSet accuracy: 0.851] [ValidSet loss: 1258.026, ValidSet accuracy: 0.850] \n","epoch: 90, [TrainSet loss: 1252.799, TrainSet accuracy: 0.850] [ValidSet loss: 1257.864, ValidSet accuracy: 0.848] \n","epoch: 91, [TrainSet loss: 1252.819, TrainSet accuracy: 0.850] [ValidSet loss: 1258.446, ValidSet accuracy: 0.849] \n","epoch: 92, [TrainSet loss: 1252.851, TrainSet accuracy: 0.850] [ValidSet loss: 1258.398, ValidSet accuracy: 0.853] \n","epoch: 93, [TrainSet loss: 1252.800, TrainSet accuracy: 0.851] [ValidSet loss: 1258.528, ValidSet accuracy: 0.847] \n","epoch: 94, [TrainSet loss: 1252.254, TrainSet accuracy: 0.850] [ValidSet loss: 1258.311, ValidSet accuracy: 0.846] \n","epoch: 95, [TrainSet loss: 1252.388, TrainSet accuracy: 0.850] [ValidSet loss: 1258.507, ValidSet accuracy: 0.854] \n","epoch: 96, [TrainSet loss: 1252.224, TrainSet accuracy: 0.850] [ValidSet loss: 1257.892, ValidSet accuracy: 0.853] \n","epoch: 97, [TrainSet loss: 1252.207, TrainSet accuracy: 0.850] [ValidSet loss: 1257.976, ValidSet accuracy: 0.852] \n","epoch: 98, [TrainSet loss: 1252.084, TrainSet accuracy: 0.850] [ValidSet loss: 1257.804, ValidSet accuracy: 0.850] \n","epoch: 99, [TrainSet loss: 1251.826, TrainSet accuracy: 0.851] [ValidSet loss: 1258.431, ValidSet accuracy: 0.849] \n","epoch: 100, [TrainSet loss: 1251.701, TrainSet accuracy: 0.850] [ValidSet loss: 1258.530, ValidSet accuracy: 0.853] \n","15:07:17\n","```"]},{"cell_type":"markdown","metadata":{"id":"CJI59-TV_i4v","colab_type":"text"},"source":["## GAN"]},{"cell_type":"code","metadata":{"id":"oF1J-s-vO_W6","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/GAN/GAN_MNIST.py\" -train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KUdC702jn5ZN","colab_type":"text"},"source":["\n","\n","```\n","2020-08-06 02:15:52.863810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-08-06 02:15:53.226926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","epoch: 1, [Dis_loss: 0.240 (Dis_loss_real: 0.389, Dis_loss_fake: 0.091), Gen_loss: 0.138] \n","epoch: 2, [Dis_loss: 0.312 (Dis_loss_real: 0.509, Dis_loss_fake: 0.115), Gen_loss: 0.554] \n","epoch: 3, [Dis_loss: 0.523 (Dis_loss_real: 0.642, Dis_loss_fake: 0.404), Gen_loss: 1.913] \n","epoch: 4, [Dis_loss: 0.535 (Dis_loss_real: 0.662, Dis_loss_fake: 0.408), Gen_loss: 1.464] \n","epoch: 5, [Dis_loss: 0.569 (Dis_loss_real: 0.689, Dis_loss_fake: 0.449), Gen_loss: 1.678] \n","epoch: 6, [Dis_loss: 0.568 (Dis_loss_real: 0.687, Dis_loss_fake: 0.449), Gen_loss: 1.794] \n","epoch: 7, [Dis_loss: 0.554 (Dis_loss_real: 0.677, Dis_loss_fake: 0.432), Gen_loss: 1.868] \n","epoch: 8, [Dis_loss: 0.574 (Dis_loss_real: 0.699, Dis_loss_fake: 0.448), Gen_loss: 1.791] \n","epoch: 9, [Dis_loss: 0.567 (Dis_loss_real: 0.694, Dis_loss_fake: 0.440), Gen_loss: 1.858] \n","epoch: 10, [Dis_loss: 0.553 (Dis_loss_real: 0.680, Dis_loss_fake: 0.426), Gen_loss: 1.825] \n","epoch: 11, [Dis_loss: 0.572 (Dis_loss_real: 0.696, Dis_loss_fake: 0.447), Gen_loss: 1.851] \n","epoch: 12, [Dis_loss: 0.567 (Dis_loss_real: 0.694, Dis_loss_fake: 0.440), Gen_loss: 1.828] \n","epoch: 13, [Dis_loss: 0.558 (Dis_loss_real: 0.681, Dis_loss_fake: 0.434), Gen_loss: 1.823] \n","epoch: 14, [Dis_loss: 0.562 (Dis_loss_real: 0.685, Dis_loss_fake: 0.439), Gen_loss: 1.814] \n","epoch: 15, [Dis_loss: 0.572 (Dis_loss_real: 0.695, Dis_loss_fake: 0.449), Gen_loss: 1.832] \n","epoch: 16, [Dis_loss: 0.557 (Dis_loss_real: 0.681, Dis_loss_fake: 0.432), Gen_loss: 1.832] \n","epoch: 17, [Dis_loss: 0.559 (Dis_loss_real: 0.680, Dis_loss_fake: 0.439), Gen_loss: 1.806] \n","epoch: 18, [Dis_loss: 0.558 (Dis_loss_real: 0.680, Dis_loss_fake: 0.437), Gen_loss: 1.809] \n","epoch: 19, [Dis_loss: 0.546 (Dis_loss_real: 0.668, Dis_loss_fake: 0.425), Gen_loss: 1.835] \n","epoch: 20, [Dis_loss: 0.564 (Dis_loss_real: 0.686, Dis_loss_fake: 0.441), Gen_loss: 1.834] \n","epoch: 21, [Dis_loss: 0.549 (Dis_loss_real: 0.669, Dis_loss_fake: 0.428), Gen_loss: 1.804] \n","epoch: 22, [Dis_loss: 0.546 (Dis_loss_real: 0.668, Dis_loss_fake: 0.425), Gen_loss: 1.854] \n","epoch: 23, [Dis_loss: 0.540 (Dis_loss_real: 0.660, Dis_loss_fake: 0.419), Gen_loss: 1.861] \n","epoch: 24, [Dis_loss: 0.534 (Dis_loss_real: 0.655, Dis_loss_fake: 0.413), Gen_loss: 1.886] \n","epoch: 25, [Dis_loss: 0.535 (Dis_loss_real: 0.656, Dis_loss_fake: 0.415), Gen_loss: 1.875] \n","epoch: 26, [Dis_loss: 0.533 (Dis_loss_real: 0.653, Dis_loss_fake: 0.413), Gen_loss: 1.881] \n","epoch: 27, [Dis_loss: 0.536 (Dis_loss_real: 0.656, Dis_loss_fake: 0.416), Gen_loss: 1.868] \n","epoch: 28, [Dis_loss: 0.530 (Dis_loss_real: 0.650, Dis_loss_fake: 0.410), Gen_loss: 1.922] \n","epoch: 29, [Dis_loss: 0.528 (Dis_loss_real: 0.648, Dis_loss_fake: 0.408), Gen_loss: 1.897] \n","epoch: 30, [Dis_loss: 0.523 (Dis_loss_real: 0.643, Dis_loss_fake: 0.402), Gen_loss: 1.949] \n","epoch: 31, [Dis_loss: 0.523 (Dis_loss_real: 0.643, Dis_loss_fake: 0.403), Gen_loss: 1.940] \n","epoch: 32, [Dis_loss: 0.518 (Dis_loss_real: 0.638, Dis_loss_fake: 0.398), Gen_loss: 1.952] \n","epoch: 33, [Dis_loss: 0.521 (Dis_loss_real: 0.641, Dis_loss_fake: 0.401), Gen_loss: 1.970] \n","epoch: 34, [Dis_loss: 0.513 (Dis_loss_real: 0.632, Dis_loss_fake: 0.393), Gen_loss: 1.962] \n","epoch: 35, [Dis_loss: 0.516 (Dis_loss_real: 0.637, Dis_loss_fake: 0.396), Gen_loss: 1.941] \n","epoch: 36, [Dis_loss: 0.507 (Dis_loss_real: 0.628, Dis_loss_fake: 0.386), Gen_loss: 2.019] \n","epoch: 37, [Dis_loss: 0.506 (Dis_loss_real: 0.627, Dis_loss_fake: 0.385), Gen_loss: 2.010] \n","epoch: 38, [Dis_loss: 0.504 (Dis_loss_real: 0.626, Dis_loss_fake: 0.382), Gen_loss: 2.042] \n","epoch: 39, [Dis_loss: 0.508 (Dis_loss_real: 0.628, Dis_loss_fake: 0.388), Gen_loss: 2.035] \n","epoch: 40, [Dis_loss: 0.497 (Dis_loss_real: 0.616, Dis_loss_fake: 0.378), Gen_loss: 2.038] \n","epoch: 41, [Dis_loss: 0.504 (Dis_loss_real: 0.626, Dis_loss_fake: 0.383), Gen_loss: 2.057] \n","epoch: 42, [Dis_loss: 0.490 (Dis_loss_real: 0.610, Dis_loss_fake: 0.370), Gen_loss: 2.062] \n","epoch: 43, [Dis_loss: 0.508 (Dis_loss_real: 0.628, Dis_loss_fake: 0.388), Gen_loss: 2.074] \n","epoch: 44, [Dis_loss: 0.495 (Dis_loss_real: 0.615, Dis_loss_fake: 0.376), Gen_loss: 2.078] \n","epoch: 45, [Dis_loss: 0.499 (Dis_loss_real: 0.620, Dis_loss_fake: 0.378), Gen_loss: 2.048] \n","epoch: 46, [Dis_loss: 0.488 (Dis_loss_real: 0.606, Dis_loss_fake: 0.369), Gen_loss: 2.100] \n","epoch: 47, [Dis_loss: 0.483 (Dis_loss_real: 0.603, Dis_loss_fake: 0.362), Gen_loss: 2.100] \n","epoch: 48, [Dis_loss: 0.490 (Dis_loss_real: 0.611, Dis_loss_fake: 0.370), Gen_loss: 2.088] \n","epoch: 49, [Dis_loss: 0.483 (Dis_loss_real: 0.603, Dis_loss_fake: 0.363), Gen_loss: 2.137] \n","epoch: 50, [Dis_loss: 0.489 (Dis_loss_real: 0.609, Dis_loss_fake: 0.369), Gen_loss: 2.140] \n","epoch: 51, [Dis_loss: 0.478 (Dis_loss_real: 0.598, Dis_loss_fake: 0.359), Gen_loss: 2.095] \n","epoch: 52, [Dis_loss: 0.493 (Dis_loss_real: 0.614, Dis_loss_fake: 0.371), Gen_loss: 2.152] \n","epoch: 53, [Dis_loss: 0.482 (Dis_loss_real: 0.601, Dis_loss_fake: 0.363), Gen_loss: 2.157] \n","epoch: 54, [Dis_loss: 0.485 (Dis_loss_real: 0.604, Dis_loss_fake: 0.365), Gen_loss: 2.128] \n","epoch: 55, [Dis_loss: 0.479 (Dis_loss_real: 0.600, Dis_loss_fake: 0.358), Gen_loss: 2.153] \n","epoch: 56, [Dis_loss: 0.475 (Dis_loss_real: 0.595, Dis_loss_fake: 0.355), Gen_loss: 2.169] \n","epoch: 57, [Dis_loss: 0.476 (Dis_loss_real: 0.597, Dis_loss_fake: 0.356), Gen_loss: 2.172] \n","epoch: 58, [Dis_loss: 0.471 (Dis_loss_real: 0.592, Dis_loss_fake: 0.351), Gen_loss: 2.183] \n","epoch: 59, [Dis_loss: 0.476 (Dis_loss_real: 0.596, Dis_loss_fake: 0.356), Gen_loss: 2.177] \n","epoch: 60, [Dis_loss: 0.483 (Dis_loss_real: 0.603, Dis_loss_fake: 0.363), Gen_loss: 2.207] \n","epoch: 61, [Dis_loss: 0.472 (Dis_loss_real: 0.593, Dis_loss_fake: 0.351), Gen_loss: 2.230] \n","epoch: 62, [Dis_loss: 0.475 (Dis_loss_real: 0.596, Dis_loss_fake: 0.354), Gen_loss: 2.206] \n","epoch: 63, [Dis_loss: 0.468 (Dis_loss_real: 0.588, Dis_loss_fake: 0.347), Gen_loss: 2.233] \n","epoch: 64, [Dis_loss: 0.475 (Dis_loss_real: 0.593, Dis_loss_fake: 0.356), Gen_loss: 2.209] \n","epoch: 65, [Dis_loss: 0.468 (Dis_loss_real: 0.587, Dis_loss_fake: 0.348), Gen_loss: 2.230] \n","epoch: 66, [Dis_loss: 0.473 (Dis_loss_real: 0.592, Dis_loss_fake: 0.354), Gen_loss: 2.205] \n","epoch: 67, [Dis_loss: 0.465 (Dis_loss_real: 0.586, Dis_loss_fake: 0.345), Gen_loss: 2.202] \n","epoch: 68, [Dis_loss: 0.479 (Dis_loss_real: 0.600, Dis_loss_fake: 0.357), Gen_loss: 2.251] \n","epoch: 69, [Dis_loss: 0.465 (Dis_loss_real: 0.585, Dis_loss_fake: 0.344), Gen_loss: 2.233] \n","epoch: 70, [Dis_loss: 0.464 (Dis_loss_real: 0.584, Dis_loss_fake: 0.344), Gen_loss: 2.235] \n","epoch: 71, [Dis_loss: 0.471 (Dis_loss_real: 0.592, Dis_loss_fake: 0.350), Gen_loss: 2.240] \n","epoch: 72, [Dis_loss: 0.472 (Dis_loss_real: 0.592, Dis_loss_fake: 0.353), Gen_loss: 2.255] \n","epoch: 73, [Dis_loss: 0.467 (Dis_loss_real: 0.588, Dis_loss_fake: 0.347), Gen_loss: 2.277] \n","epoch: 74, [Dis_loss: 0.468 (Dis_loss_real: 0.588, Dis_loss_fake: 0.347), Gen_loss: 2.232] \n","epoch: 75, [Dis_loss: 0.468 (Dis_loss_real: 0.587, Dis_loss_fake: 0.348), Gen_loss: 2.251] \n","epoch: 76, [Dis_loss: 0.463 (Dis_loss_real: 0.583, Dis_loss_fake: 0.343), Gen_loss: 2.274] \n","epoch: 77, [Dis_loss: 0.466 (Dis_loss_real: 0.586, Dis_loss_fake: 0.346), Gen_loss: 2.260] \n","epoch: 78, [Dis_loss: 0.464 (Dis_loss_real: 0.584, Dis_loss_fake: 0.344), Gen_loss: 2.246] \n","epoch: 79, [Dis_loss: 0.459 (Dis_loss_real: 0.579, Dis_loss_fake: 0.339), Gen_loss: 2.249] \n","epoch: 80, [Dis_loss: 0.462 (Dis_loss_real: 0.583, Dis_loss_fake: 0.341), Gen_loss: 2.272] \n","epoch: 81, [Dis_loss: 0.461 (Dis_loss_real: 0.582, Dis_loss_fake: 0.340), Gen_loss: 2.270] \n","epoch: 82, [Dis_loss: 0.473 (Dis_loss_real: 0.593, Dis_loss_fake: 0.352), Gen_loss: 2.299] \n","epoch: 83, [Dis_loss: 0.465 (Dis_loss_real: 0.586, Dis_loss_fake: 0.344), Gen_loss: 2.282] \n","epoch: 84, [Dis_loss: 0.460 (Dis_loss_real: 0.579, Dis_loss_fake: 0.340), Gen_loss: 2.293] \n","epoch: 85, [Dis_loss: 0.467 (Dis_loss_real: 0.587, Dis_loss_fake: 0.347), Gen_loss: 2.290] \n","epoch: 86, [Dis_loss: 0.466 (Dis_loss_real: 0.585, Dis_loss_fake: 0.347), Gen_loss: 2.294] \n","epoch: 87, [Dis_loss: 0.456 (Dis_loss_real: 0.576, Dis_loss_fake: 0.335), Gen_loss: 2.286] \n","epoch: 88, [Dis_loss: 0.456 (Dis_loss_real: 0.577, Dis_loss_fake: 0.334), Gen_loss: 2.304] \n","epoch: 89, [Dis_loss: 0.459 (Dis_loss_real: 0.580, Dis_loss_fake: 0.338), Gen_loss: 2.289] \n","epoch: 90, [Dis_loss: 0.469 (Dis_loss_real: 0.591, Dis_loss_fake: 0.347), Gen_loss: 2.317] \n","epoch: 91, [Dis_loss: 0.458 (Dis_loss_real: 0.580, Dis_loss_fake: 0.337), Gen_loss: 2.290] \n","epoch: 92, [Dis_loss: 0.486 (Dis_loss_real: 0.610, Dis_loss_fake: 0.361), Gen_loss: 2.322] \n","epoch: 93, [Dis_loss: 0.452 (Dis_loss_real: 0.572, Dis_loss_fake: 0.332), Gen_loss: 2.241] \n","epoch: 94, [Dis_loss: 0.454 (Dis_loss_real: 0.574, Dis_loss_fake: 0.334), Gen_loss: 2.280] \n","epoch: 95, [Dis_loss: 0.464 (Dis_loss_real: 0.585, Dis_loss_fake: 0.344), Gen_loss: 2.286] \n","epoch: 96, [Dis_loss: 0.453 (Dis_loss_real: 0.574, Dis_loss_fake: 0.333), Gen_loss: 2.305] \n","epoch: 97, [Dis_loss: 0.458 (Dis_loss_real: 0.579, Dis_loss_fake: 0.336), Gen_loss: 2.283] \n","epoch: 98, [Dis_loss: 0.458 (Dis_loss_real: 0.580, Dis_loss_fake: 0.336), Gen_loss: 2.302] \n","epoch: 99, [Dis_loss: 0.456 (Dis_loss_real: 0.577, Dis_loss_fake: 0.335), Gen_loss: 2.341] \n","epoch: 100, [Dis_loss: 0.461 (Dis_loss_real: 0.582, Dis_loss_fake: 0.340), Gen_loss: 2.310] \n","02:32:07```\n","\n"]},{"cell_type":"code","metadata":{"id":"9ZFtwJDKHg5E","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/GAN/GAN_CELEBA.py\" -train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-N_KhwwpjGRL","colab_type":"text"},"source":["\n","\n","```\n","2020-08-06 01:13:21.854305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-08-06 01:13:22.154049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","epoch: 1, [Dis_loss: 0.278 (Dis_loss_real: 0.489, Dis_loss_fake: 0.068), Gen_loss: 0.395] \n","epoch: 2, [Dis_loss: 0.330 (Dis_loss_real: 0.565, Dis_loss_fake: 0.096), Gen_loss: 1.753] \n","epoch: 3, [Dis_loss: 0.894 (Dis_loss_real: 1.089, Dis_loss_fake: 0.699), Gen_loss: 2.718] \n","epoch: 4, [Dis_loss: 0.747 (Dis_loss_real: 0.905, Dis_loss_fake: 0.588), Gen_loss: 1.898] \n","epoch: 5, [Dis_loss: 0.823 (Dis_loss_real: 0.968, Dis_loss_fake: 0.677), Gen_loss: 1.465] \n","epoch: 6, [Dis_loss: 0.823 (Dis_loss_real: 0.951, Dis_loss_fake: 0.695), Gen_loss: 1.581] \n","epoch: 7, [Dis_loss: 0.776 (Dis_loss_real: 0.896, Dis_loss_fake: 0.656), Gen_loss: 1.577] \n","epoch: 8, [Dis_loss: 0.738 (Dis_loss_real: 0.851, Dis_loss_fake: 0.624), Gen_loss: 1.594] \n","epoch: 9, [Dis_loss: 0.704 (Dis_loss_real: 0.818, Dis_loss_fake: 0.590), Gen_loss: 1.779] \n","epoch: 10, [Dis_loss: 0.639 (Dis_loss_real: 0.755, Dis_loss_fake: 0.523), Gen_loss: 1.618] \n","epoch: 11, [Dis_loss: 0.459 (Dis_loss_real: 0.593, Dis_loss_fake: 0.325), Gen_loss: 1.037] \n","epoch: 12, [Dis_loss: 0.471 (Dis_loss_real: 0.613, Dis_loss_fake: 0.328), Gen_loss: 0.969] \n","epoch: 13, [Dis_loss: 0.410 (Dis_loss_real: 0.573, Dis_loss_fake: 0.247), Gen_loss: 0.652] \n","epoch: 14, [Dis_loss: 0.305 (Dis_loss_real: 0.468, Dis_loss_fake: 0.141), Gen_loss: 0.368] \n","epoch: 15, [Dis_loss: 0.368 (Dis_loss_real: 0.529, Dis_loss_fake: 0.207), Gen_loss: 0.564] \n","epoch: 16, [Dis_loss: 0.380 (Dis_loss_real: 0.543, Dis_loss_fake: 0.216), Gen_loss: 0.604] \n","epoch: 17, [Dis_loss: 0.335 (Dis_loss_real: 0.507, Dis_loss_fake: 0.162), Gen_loss: 0.426] \n","epoch: 18, [Dis_loss: 0.329 (Dis_loss_real: 0.512, Dis_loss_fake: 0.146), Gen_loss: 0.422] \n","epoch: 19, [Dis_loss: 0.389 (Dis_loss_real: 0.561, Dis_loss_fake: 0.217), Gen_loss: 0.416] \n","epoch: 20, [Dis_loss: 0.385 (Dis_loss_real: 0.548, Dis_loss_fake: 0.221), Gen_loss: 0.583] \n","epoch: 21, [Dis_loss: 0.372 (Dis_loss_real: 0.528, Dis_loss_fake: 0.215), Gen_loss: 0.393] \n","epoch: 22, [Dis_loss: 0.383 (Dis_loss_real: 0.548, Dis_loss_fake: 0.218), Gen_loss: 0.409] \n","epoch: 23, [Dis_loss: 0.495 (Dis_loss_real: 0.648, Dis_loss_fake: 0.341), Gen_loss: 0.575] \n","epoch: 24, [Dis_loss: 0.480 (Dis_loss_real: 0.632, Dis_loss_fake: 0.327), Gen_loss: 0.953] \n","epoch: 25, [Dis_loss: 0.446 (Dis_loss_real: 0.591, Dis_loss_fake: 0.301), Gen_loss: 0.656] \n","epoch: 26, [Dis_loss: 0.523 (Dis_loss_real: 0.665, Dis_loss_fake: 0.381), Gen_loss: 0.770] \n","epoch: 27, [Dis_loss: 0.469 (Dis_loss_real: 0.611, Dis_loss_fake: 0.327), Gen_loss: 0.722] \n","epoch: 28, [Dis_loss: 0.420 (Dis_loss_real: 0.580, Dis_loss_fake: 0.259), Gen_loss: 0.565] \n","epoch: 29, [Dis_loss: 0.461 (Dis_loss_real: 0.602, Dis_loss_fake: 0.320), Gen_loss: 0.787] \n","epoch: 30, [Dis_loss: 0.406 (Dis_loss_real: 0.554, Dis_loss_fake: 0.258), Gen_loss: 0.533] \n","epoch: 31, [Dis_loss: 0.385 (Dis_loss_real: 0.536, Dis_loss_fake: 0.235), Gen_loss: 0.548] \n","epoch: 32, [Dis_loss: 0.452 (Dis_loss_real: 0.605, Dis_loss_fake: 0.299), Gen_loss: 0.645] \n","epoch: 33, [Dis_loss: 0.443 (Dis_loss_real: 0.596, Dis_loss_fake: 0.290), Gen_loss: 0.610] \n","epoch: 34, [Dis_loss: 0.455 (Dis_loss_real: 0.610, Dis_loss_fake: 0.299), Gen_loss: 0.648] \n","epoch: 35, [Dis_loss: 0.303 (Dis_loss_real: 0.461, Dis_loss_fake: 0.144), Gen_loss: 0.358] \n","epoch: 36, [Dis_loss: 0.355 (Dis_loss_real: 0.519, Dis_loss_fake: 0.192), Gen_loss: 0.528] \n","epoch: 37, [Dis_loss: 0.385 (Dis_loss_real: 0.529, Dis_loss_fake: 0.241), Gen_loss: 0.379] \n","epoch: 38, [Dis_loss: 0.315 (Dis_loss_real: 0.485, Dis_loss_fake: 0.146), Gen_loss: 0.304] \n","epoch: 39, [Dis_loss: 0.344 (Dis_loss_real: 0.496, Dis_loss_fake: 0.191), Gen_loss: 0.334] \n","epoch: 40, [Dis_loss: 0.350 (Dis_loss_real: 0.515, Dis_loss_fake: 0.184), Gen_loss: 0.445] \n","epoch: 41, [Dis_loss: 0.383 (Dis_loss_real: 0.537, Dis_loss_fake: 0.229), Gen_loss: 0.353] \n","epoch: 42, [Dis_loss: 0.395 (Dis_loss_real: 0.546, Dis_loss_fake: 0.244), Gen_loss: 0.865] \n","epoch: 43, [Dis_loss: 0.449 (Dis_loss_real: 0.591, Dis_loss_fake: 0.307), Gen_loss: 0.589] \n","epoch: 44, [Dis_loss: 0.445 (Dis_loss_real: 0.596, Dis_loss_fake: 0.294), Gen_loss: 0.675] \n","epoch: 45, [Dis_loss: 0.448 (Dis_loss_real: 0.603, Dis_loss_fake: 0.292), Gen_loss: 0.564] \n","epoch: 46, [Dis_loss: 0.419 (Dis_loss_real: 0.571, Dis_loss_fake: 0.268), Gen_loss: 0.681] \n","epoch: 47, [Dis_loss: 0.455 (Dis_loss_real: 0.593, Dis_loss_fake: 0.317), Gen_loss: 0.728] \n","epoch: 48, [Dis_loss: 0.492 (Dis_loss_real: 0.622, Dis_loss_fake: 0.361), Gen_loss: 0.895] \n","epoch: 49, [Dis_loss: 0.627 (Dis_loss_real: 0.749, Dis_loss_fake: 0.506), Gen_loss: 1.475] \n","epoch: 50, [Dis_loss: 0.379 (Dis_loss_real: 0.524, Dis_loss_fake: 0.234), Gen_loss: 0.512] \n","epoch: 51, [Dis_loss: 0.582 (Dis_loss_real: 0.705, Dis_loss_fake: 0.459), Gen_loss: 1.219] \n","epoch: 52, [Dis_loss: 0.533 (Dis_loss_real: 0.664, Dis_loss_fake: 0.403), Gen_loss: 1.092] \n","epoch: 53, [Dis_loss: 0.580 (Dis_loss_real: 0.699, Dis_loss_fake: 0.461), Gen_loss: 1.463] \n","epoch: 54, [Dis_loss: 0.455 (Dis_loss_real: 0.598, Dis_loss_fake: 0.312), Gen_loss: 0.824] \n","epoch: 55, [Dis_loss: 0.471 (Dis_loss_real: 0.603, Dis_loss_fake: 0.338), Gen_loss: 0.916] \n","epoch: 56, [Dis_loss: 0.534 (Dis_loss_real: 0.659, Dis_loss_fake: 0.409), Gen_loss: 1.253] \n","epoch: 57, [Dis_loss: 0.582 (Dis_loss_real: 0.700, Dis_loss_fake: 0.465), Gen_loss: 1.430] \n","epoch: 58, [Dis_loss: 0.482 (Dis_loss_real: 0.611, Dis_loss_fake: 0.352), Gen_loss: 1.069] \n","epoch: 59, [Dis_loss: 0.599 (Dis_loss_real: 0.710, Dis_loss_fake: 0.489), Gen_loss: 1.698] \n","epoch: 60, [Dis_loss: 0.541 (Dis_loss_real: 0.664, Dis_loss_fake: 0.419), Gen_loss: 1.556] \n","epoch: 61, [Dis_loss: 0.516 (Dis_loss_real: 0.636, Dis_loss_fake: 0.396), Gen_loss: 1.662] \n","epoch: 62, [Dis_loss: 0.571 (Dis_loss_real: 0.685, Dis_loss_fake: 0.457), Gen_loss: 1.848] \n","epoch: 63, [Dis_loss: 0.551 (Dis_loss_real: 0.668, Dis_loss_fake: 0.434), Gen_loss: 1.801] \n","epoch: 64, [Dis_loss: 0.569 (Dis_loss_real: 0.682, Dis_loss_fake: 0.456), Gen_loss: 1.944] \n","epoch: 65, [Dis_loss: 0.521 (Dis_loss_real: 0.639, Dis_loss_fake: 0.404), Gen_loss: 1.854] \n","epoch: 66, [Dis_loss: 0.543 (Dis_loss_real: 0.659, Dis_loss_fake: 0.427), Gen_loss: 2.036] \n","epoch: 67, [Dis_loss: 0.469 (Dis_loss_real: 0.599, Dis_loss_fake: 0.340), Gen_loss: 1.644] \n","epoch: 68, [Dis_loss: 0.524 (Dis_loss_real: 0.644, Dis_loss_fake: 0.405), Gen_loss: 2.130] \n","epoch: 69, [Dis_loss: 0.524 (Dis_loss_real: 0.642, Dis_loss_fake: 0.406), Gen_loss: 2.120] \n","epoch: 70, [Dis_loss: 0.459 (Dis_loss_real: 0.589, Dis_loss_fake: 0.329), Gen_loss: 1.743] \n","epoch: 71, [Dis_loss: 0.484 (Dis_loss_real: 0.611, Dis_loss_fake: 0.358), Gen_loss: 2.031] \n","epoch: 72, [Dis_loss: 0.493 (Dis_loss_real: 0.614, Dis_loss_fake: 0.372), Gen_loss: 2.145] \n","epoch: 73, [Dis_loss: 0.392 (Dis_loss_real: 0.531, Dis_loss_fake: 0.253), Gen_loss: 1.691] \n","epoch: 74, [Dis_loss: 0.425 (Dis_loss_real: 0.570, Dis_loss_fake: 0.280), Gen_loss: 1.677] \n","epoch: 75, [Dis_loss: 0.495 (Dis_loss_real: 0.621, Dis_loss_fake: 0.370), Gen_loss: 2.266] \n","epoch: 76, [Dis_loss: 0.468 (Dis_loss_real: 0.593, Dis_loss_fake: 0.343), Gen_loss: 2.232] \n","epoch: 77, [Dis_loss: 0.461 (Dis_loss_real: 0.588, Dis_loss_fake: 0.334), Gen_loss: 2.377] \n","epoch: 78, [Dis_loss: 0.449 (Dis_loss_real: 0.576, Dis_loss_fake: 0.322), Gen_loss: 2.422] \n","epoch: 79, [Dis_loss: 0.438 (Dis_loss_real: 0.570, Dis_loss_fake: 0.306), Gen_loss: 2.086] \n","epoch: 80, [Dis_loss: 0.449 (Dis_loss_real: 0.577, Dis_loss_fake: 0.322), Gen_loss: 2.434] \n","epoch: 81, [Dis_loss: 0.453 (Dis_loss_real: 0.584, Dis_loss_fake: 0.321), Gen_loss: 2.368] \n","epoch: 82, [Dis_loss: 0.449 (Dis_loss_real: 0.576, Dis_loss_fake: 0.322), Gen_loss: 2.565] \n","epoch: 83, [Dis_loss: 0.439 (Dis_loss_real: 0.576, Dis_loss_fake: 0.302), Gen_loss: 2.232] \n","epoch: 84, [Dis_loss: 0.399 (Dis_loss_real: 0.533, Dis_loss_fake: 0.264), Gen_loss: 2.231] \n","epoch: 85, [Dis_loss: 0.404 (Dis_loss_real: 0.543, Dis_loss_fake: 0.265), Gen_loss: 2.201] \n","epoch: 86, [Dis_loss: 0.404 (Dis_loss_real: 0.540, Dis_loss_fake: 0.267), Gen_loss: 2.061] \n","epoch: 87, [Dis_loss: 0.456 (Dis_loss_real: 0.589, Dis_loss_fake: 0.323), Gen_loss: 2.502] \n","epoch: 88, [Dis_loss: 0.386 (Dis_loss_real: 0.532, Dis_loss_fake: 0.240), Gen_loss: 1.998] \n","epoch: 89, [Dis_loss: 0.414 (Dis_loss_real: 0.550, Dis_loss_fake: 0.278), Gen_loss: 2.493] \n","epoch: 90, [Dis_loss: 0.418 (Dis_loss_real: 0.559, Dis_loss_fake: 0.276), Gen_loss: 2.255] \n","epoch: 91, [Dis_loss: 0.396 (Dis_loss_real: 0.530, Dis_loss_fake: 0.262), Gen_loss: 2.472] \n","epoch: 92, [Dis_loss: 0.435 (Dis_loss_real: 0.571, Dis_loss_fake: 0.299), Gen_loss: 2.657] \n","epoch: 93, [Dis_loss: 0.397 (Dis_loss_real: 0.535, Dis_loss_fake: 0.259), Gen_loss: 2.153] \n","epoch: 94, [Dis_loss: 0.406 (Dis_loss_real: 0.541, Dis_loss_fake: 0.271), Gen_loss: 2.571] \n","epoch: 95, [Dis_loss: 0.431 (Dis_loss_real: 0.573, Dis_loss_fake: 0.289), Gen_loss: 2.553] \n","epoch: 96, [Dis_loss: 0.366 (Dis_loss_real: 0.508, Dis_loss_fake: 0.223), Gen_loss: 2.168] \n","epoch: 97, [Dis_loss: 0.408 (Dis_loss_real: 0.544, Dis_loss_fake: 0.272), Gen_loss: 2.585] \n","epoch: 98, [Dis_loss: 0.426 (Dis_loss_real: 0.562, Dis_loss_fake: 0.289), Gen_loss: 2.646] \n","epoch: 99, [Dis_loss: 0.393 (Dis_loss_real: 0.532, Dis_loss_fake: 0.253), Gen_loss: 2.547] \n","epoch: 100, [Dis_loss: 0.424 (Dis_loss_real: 0.560, Dis_loss_fake: 0.289), Gen_loss: 2.828] \n","01:53:48\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rOzvIENf_kdK","colab_type":"text"},"source":["## VAE-GAN "]},{"cell_type":"code","metadata":{"id":"da-fshtcftHW","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE-GAN/VAE_GAN_MNIST.py\" -train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HG6OiLkVZQB","colab_type":"text"},"source":["```\n","2020-08-01 15:51:31.570674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-08-01 15:51:33.253493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","epoch: 1 kl_loss: 0.008827543258666993 rec_loss: 5772.146492745535 gen_loss: 1.2703731407438006 dis_loss: 2.058787238938468\n","epoch: 2 kl_loss: 0.1975441677229745 rec_loss: 5784.105979352678 gen_loss: 1.329868368421282 dis_loss: 1.8968137686593192\n","epoch: 3 kl_loss: 0.2918863352707454 rec_loss: 5788.93515625 gen_loss: 1.3391577420915877 dis_loss: 1.9797648027965\n","epoch: 4 kl_loss: 0.9131040232522147 rec_loss: 5786.185845424107 gen_loss: 1.3460091127668108 dis_loss: 2.0027474117279054\n","epoch: 5 kl_loss: 1.7972441952569145 rec_loss: 5818.4868889508925 gen_loss: 1.3660014537402563 dis_loss: 1.768685530935015\n","epoch: 6 kl_loss: 1.6263653656414576 rec_loss: 5798.982801339285 gen_loss: 1.347418222427368 dis_loss: 2.0434565571376258\n","epoch: 7 kl_loss: 2.6079105520248413 rec_loss: 5805.318582589286 gen_loss: 1.3401484768731253 dis_loss: 1.9714989921024868\n","epoch: 8 kl_loss: 3.961366570336478 rec_loss: 5810.8448911830355 gen_loss: 1.3352099391392298 dis_loss: 1.9294366843359811\n","epoch: 9 kl_loss: 6.042594225747245 rec_loss: 5818.48310546875 gen_loss: 1.3320191301618303 dis_loss: 1.903467914036342\n","epoch: 10 kl_loss: 8.282567370278494 rec_loss: 5817.634296875 gen_loss: 1.3314224890300206 dis_loss: 1.9271893671580724\n","epoch: 11 kl_loss: 10.193584826333183 rec_loss: 5818.7253515625 gen_loss: 1.329939193725586 dis_loss: 1.9546801437650407\n","epoch: 12 kl_loss: 11.911457301548548 rec_loss: 5815.512991071429 gen_loss: 1.3307527467182705 dis_loss: 1.9521322788511004\n","epoch: 13 kl_loss: 13.39472414289202 rec_loss: 5812.94408203125 gen_loss: 1.3259758751732962 dis_loss: 1.9670593357086181\n","epoch: 14 kl_loss: 14.232184284755162 rec_loss: 5809.946171875 gen_loss: 1.325222088950021 dis_loss: 1.9713900388990129\n","epoch: 15 kl_loss: 14.746992372785297 rec_loss: 5808.472008928571 gen_loss: 1.3247196360996791 dis_loss: 1.9641870301110405\n","epoch: 16 kl_loss: 15.583210111345563 rec_loss: 5807.705546875 gen_loss: 1.3244370651245116 dis_loss: 1.9714289794649396\n","epoch: 17 kl_loss: 16.241314353942872 rec_loss: 5807.0065625 gen_loss: 1.324820978982108 dis_loss: 1.963850393976484\n","epoch: 18 kl_loss: 17.150653070722306 rec_loss: 5806.726573660714 gen_loss: 1.3232387563160488 dis_loss: 1.9751989323752268\n","epoch: 19 kl_loss: 17.94736796787807 rec_loss: 5806.533482142857 gen_loss: 1.3257444231850761 dis_loss: 1.9711544833864485\n","epoch: 20 kl_loss: 18.59823127746582 rec_loss: 5806.420859375 gen_loss: 1.3252483858381 dis_loss: 1.9691953468322754\n","epoch: 21 kl_loss: 19.023022886003766 rec_loss: 5806.23828125 gen_loss: 1.3250083936963764 dis_loss: 1.9634526715959821\n","epoch: 22 kl_loss: 19.441653104509626 rec_loss: 5806.046648995536 gen_loss: 1.3277155562809535 dis_loss: 1.9611784934997558\n","epoch: 23 kl_loss: 19.810332172938754 rec_loss: 5806.284483816964 gen_loss: 1.3273404278073992 dis_loss: 1.96254545211792\n","epoch: 24 kl_loss: 20.05637107849121 rec_loss: 5806.348074776785 gen_loss: 1.32888637815203 dis_loss: 1.9675241034371511\n","epoch: 25 kl_loss: 20.33381877354213 rec_loss: 5806.131358816964 gen_loss: 1.3289200292314802 dis_loss: 1.9691707338605609\n","epoch: 26 kl_loss: 20.57516722542899 rec_loss: 5806.323741629464 gen_loss: 1.3289831720079694 dis_loss: 1.9735160650525774\n","epoch: 27 kl_loss: 20.688118667602538 rec_loss: 5806.300184151785 gen_loss: 1.3306457887377057 dis_loss: 1.976938316481454\n","epoch: 28 kl_loss: 20.8609846169608 rec_loss: 5806.248819754464 gen_loss: 1.3312973703656878 dis_loss: 1.982160189492362\n","epoch: 29 kl_loss: 21.108664845057895 rec_loss: 5806.0649469866075 gen_loss: 1.3316320514678954 dis_loss: 1.9837746388571602\n","epoch: 30 kl_loss: 21.175805500575475 rec_loss: 5805.950853794643 gen_loss: 1.3319861371176585 dis_loss: 1.9879457487378802\n","epoch: 31 kl_loss: 21.325148577008928 rec_loss: 5806.080153459821 gen_loss: 1.3326834992000034 dis_loss: 1.9908338587624685\n","epoch: 32 kl_loss: 21.438909824916294 rec_loss: 5805.703755580357 gen_loss: 1.3331201369421823 dis_loss: 1.9927211591175624\n","epoch: 33 kl_loss: 21.459059284755163 rec_loss: 5805.405080915179 gen_loss: 1.3347299262455532 dis_loss: 1.994277856690543\n","epoch: 34 kl_loss: 21.512825666155134 rec_loss: 5805.184860491071 gen_loss: 1.3361153834206718 dis_loss: 1.995750708580017\n","epoch: 35 kl_loss: 21.487857044764926 rec_loss: 5804.873384486607 gen_loss: 1.3365357317243303 dis_loss: 1.9970012181145804\n","epoch: 36 kl_loss: 21.53783721923828 rec_loss: 5804.528850446429 gen_loss: 1.3369268492289952 dis_loss: 1.997249756540571\n","epoch: 37 kl_loss: 21.560178560529437 rec_loss: 5804.3207142857145 gen_loss: 1.3370334352765765 dis_loss: 1.9971972649438041\n","epoch: 38 kl_loss: 21.603898380824496 rec_loss: 5804.297823660714 gen_loss: 1.3374637413024901 dis_loss: 1.9970714017323086\n","epoch: 39 kl_loss: 21.548911841256277 rec_loss: 5804.289411272322 gen_loss: 1.3386449173518589 dis_loss: 1.9981026159014021\n","epoch: 40 kl_loss: 21.613122525896344 rec_loss: 5804.119500558036 gen_loss: 1.3385416950498308 dis_loss: 1.998073399407523\n","epoch: 41 kl_loss: 21.65818113054548 rec_loss: 5804.1811467633925 gen_loss: 1.3393408605030606 dis_loss: 1.9973861088071552\n","epoch: 42 kl_loss: 21.607342060634068 rec_loss: 5804.0581780133925 gen_loss: 1.3392896774836949 dis_loss: 2.0001517731802805\n","epoch: 43 kl_loss: 21.685810797555106 rec_loss: 5804.201844308036 gen_loss: 1.3394704743794033 dis_loss: 1.997221428326198\n","epoch: 44 kl_loss: 21.696139057704382 rec_loss: 5804.142536272321 gen_loss: 1.340205888748169 dis_loss: 1.9985309389659336\n","epoch: 45 kl_loss: 21.73407868521554 rec_loss: 5804.217209821429 gen_loss: 1.340266673224313 dis_loss: 1.9966398286819458\n","epoch: 46 kl_loss: 21.738512529645647 rec_loss: 5804.2169140625 gen_loss: 1.3411620937074933 dis_loss: 1.9988227449144635\n","epoch: 47 kl_loss: 21.720623201642717 rec_loss: 5804.231397879465 gen_loss: 1.3412250239508492 dis_loss: 1.9966974912370954\n","epoch: 48 kl_loss: 21.679221812656948 rec_loss: 5804.035382254464 gen_loss: 1.3404566512789045 dis_loss: 1.9971179144723075\n","epoch: 49 kl_loss: 21.67820390973772 rec_loss: 5804.2030915178575 gen_loss: 1.342195085797991 dis_loss: 1.9949228749956402\n","epoch: 50 kl_loss: 21.741841506958007 rec_loss: 5804.472589285714 gen_loss: 1.3419286217008317 dis_loss: 1.9952978222710747\n","epoch: 51 kl_loss: 21.742134007045202 rec_loss: 5804.483875558036 gen_loss: 1.3416417176382882 dis_loss: 1.9952122027533394\n","epoch: 52 kl_loss: 21.803041447230747 rec_loss: 5804.715435267857 gen_loss: 1.342003264427185 dis_loss: 1.9946530914306642\n","epoch: 53 kl_loss: 21.847223390851703 rec_loss: 5804.95337890625 gen_loss: 1.342405994279044 dis_loss: 1.9936820363998413\n","epoch: 54 kl_loss: 21.90157648359026 rec_loss: 5804.979634486607 gen_loss: 1.3424586582183837 dis_loss: 1.9948427220753262\n","epoch: 55 kl_loss: 21.963772953578403 rec_loss: 5805.1894587053575 gen_loss: 1.3428136369160244 dis_loss: 1.9934021704537528\n","epoch: 56 kl_loss: 22.006672951834542 rec_loss: 5805.498231026786 gen_loss: 1.3428782783235822 dis_loss: 1.9924933644703455\n","epoch: 57 kl_loss: 22.142799737112863 rec_loss: 5805.778172433036 gen_loss: 1.34200526373727 dis_loss: 1.9926120097296578\n","epoch: 58 kl_loss: 22.14098645891462 rec_loss: 5805.866888950893 gen_loss: 1.342194753374372 dis_loss: 1.9924941512516567\n","epoch: 59 kl_loss: 22.254113529750278 rec_loss: 5806.186512276786 gen_loss: 1.3424585281099592 dis_loss: 1.9913504089627947\n","epoch: 60 kl_loss: 22.251812515258788 rec_loss: 5806.454637276785 gen_loss: 1.3408998734610422 dis_loss: 1.9927679225376673\n","epoch: 61 kl_loss: 22.34574043273926 rec_loss: 5806.623074776786 gen_loss: 1.3414399433135986 dis_loss: 1.9897900915145874\n","epoch: 62 kl_loss: 22.37476346697126 rec_loss: 5806.816194196429 gen_loss: 1.3416127245766776 dis_loss: 1.9902521453584943\n","epoch: 63 kl_loss: 22.356395928519113 rec_loss: 5806.875831473214 gen_loss: 1.3409030907494681 dis_loss: 1.9900333554404122\n","epoch: 64 kl_loss: 22.47343140738351 rec_loss: 5807.160703125 gen_loss: 1.3411457620348248 dis_loss: 1.9902704054968698\n","epoch: 65 kl_loss: 22.630809849330358 rec_loss: 5807.374341517857 gen_loss: 1.340786658695766 dis_loss: 1.9902375555038452\n","epoch: 66 kl_loss: 22.717183173043388 rec_loss: 5807.394503348214 gen_loss: 1.3404142093658447 dis_loss: 1.9910128416333879\n","epoch: 67 kl_loss: 22.716384942190988 rec_loss: 5807.524665178571 gen_loss: 1.3400846426827566 dis_loss: 1.989477790423802\n","epoch: 68 kl_loss: 22.86274814060756 rec_loss: 5807.480864955357 gen_loss: 1.3389335639136177 dis_loss: 1.988080781527928\n","epoch: 69 kl_loss: 22.888015932355607 rec_loss: 5807.49107421875 gen_loss: 1.3395414073126657 dis_loss: 1.9893202148165021\n","epoch: 70 kl_loss: 23.023092618669782 rec_loss: 5807.6651116071425 gen_loss: 1.3387665333066667 dis_loss: 1.9894167879649571\n","epoch: 71 kl_loss: 23.089189028058733 rec_loss: 5807.931643415179 gen_loss: 1.337032563345773 dis_loss: 1.9868999331338064\n","epoch: 72 kl_loss: 23.197205679757253 rec_loss: 5808.0163309151785 gen_loss: 1.3385872677394322 dis_loss: 1.9867743035725185\n","epoch: 73 kl_loss: 23.301387470790317 rec_loss: 5808.242120535714 gen_loss: 1.3379239395686557 dis_loss: 1.9860723842893329\n","epoch: 74 kl_loss: 23.36261221749442 rec_loss: 5808.448130580357 gen_loss: 1.3377772051947459 dis_loss: 1.9870592246736798\n","epoch: 75 kl_loss: 23.47204248700823 rec_loss: 5808.488409598214 gen_loss: 1.3378248487200055 dis_loss: 1.9861084079742433\n","epoch: 76 kl_loss: 23.51733706883022 rec_loss: 5808.649185267857 gen_loss: 1.3364535113743374 dis_loss: 1.9855707141331265\n","epoch: 77 kl_loss: 23.613222950526644 rec_loss: 5808.675359933036 gen_loss: 1.337744539805821 dis_loss: 1.9856902292796543\n","epoch: 78 kl_loss: 23.618724779401507 rec_loss: 5808.89802734375 gen_loss: 1.3369054671696254 dis_loss: 1.9852510125296456\n","epoch: 79 kl_loss: 23.72650386265346 rec_loss: 5809.075616629464 gen_loss: 1.337386040006365 dis_loss: 1.9843690579278128\n","epoch: 80 kl_loss: 23.773295113699778 rec_loss: 5809.115772879464 gen_loss: 1.3377126550674439 dis_loss: 1.9852605022702898\n","epoch: 81 kl_loss: 23.83323976789202 rec_loss: 5809.272433035714 gen_loss: 1.336510627610343 dis_loss: 1.9833718504224505\n","epoch: 82 kl_loss: 23.912315052577426 rec_loss: 5809.628155691964 gen_loss: 1.33676162311009 dis_loss: 1.9825355911254883\n","epoch: 83 kl_loss: 23.953530905587332 rec_loss: 5809.807028459822 gen_loss: 1.3358739532743182 dis_loss: 1.9853746461868287\n","epoch: 84 kl_loss: 24.001437301635743 rec_loss: 5809.973582589286 gen_loss: 1.33525481905256 dis_loss: 1.9833004583631244\n","epoch: 85 kl_loss: 24.113646087646483 rec_loss: 5810.143219866071 gen_loss: 1.335987319265093 dis_loss: 1.9831221880231584\n","epoch: 86 kl_loss: 24.219092112949916 rec_loss: 5810.418842075893 gen_loss: 1.336590232167925 dis_loss: 1.9800486952917917\n","epoch: 87 kl_loss: 24.237079980032785 rec_loss: 5810.651336495535 gen_loss: 1.3363461739676339 dis_loss: 1.981946907724653\n","epoch: 88 kl_loss: 24.271429792131695 rec_loss: 5810.92921875 gen_loss: 1.3349956335340227 dis_loss: 1.979784766605922\n","epoch: 89 kl_loss: 24.376647186279296 rec_loss: 5811.202915736607 gen_loss: 1.335667392866952 dis_loss: 1.9816956050055368\n","epoch: 90 kl_loss: 24.47299802507673 rec_loss: 5811.459709821429 gen_loss: 1.3365225757871355 dis_loss: 1.9829705354145595\n","epoch: 91 kl_loss: 24.525401436941966 rec_loss: 5811.532474888393 gen_loss: 1.3351969255719867 dis_loss: 1.9827655056544713\n","epoch: 92 kl_loss: 24.642255303519114 rec_loss: 5811.789232700893 gen_loss: 1.3353258541652135 dis_loss: 1.9822465085983276\n","epoch: 93 kl_loss: 24.690554406302315 rec_loss: 5812.072859933036 gen_loss: 1.336042628969465 dis_loss: 1.980923649242946\n","epoch: 94 kl_loss: 24.732710821969167 rec_loss: 5812.09857421875 gen_loss: 1.3364190639768327 dis_loss: 1.9818915224075317\n","epoch: 95 kl_loss: 24.835014114379884 rec_loss: 5812.156010044643 gen_loss: 1.3351863595417568 dis_loss: 1.9803556857790265\n","epoch: 96 kl_loss: 24.944781777518138 rec_loss: 5812.606540178572 gen_loss: 1.3343781008039202 dis_loss: 1.9809525905336653\n","epoch: 97 kl_loss: 24.997628718784878 rec_loss: 5812.717857142857 gen_loss: 1.3356233705793108 dis_loss: 1.9797609887804304\n","epoch: 98 kl_loss: 25.050425545828684 rec_loss: 5812.685304129464 gen_loss: 1.3352059050968714 dis_loss: 1.9809090062550136\n","epoch: 99 kl_loss: 25.126409083775112 rec_loss: 5812.764054129464 gen_loss: 1.335426186152867 dis_loss: 1.9814039802551269\n","epoch: 100 kl_loss: 25.216652199881416 rec_loss: 5812.876579241071 gen_loss: 1.3346804223741804 dis_loss: 1.981334820474897\n","16:26:49\n","```"]},{"cell_type":"code","metadata":{"id":"dyd1M8a79ip2","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/VAE-GAN/VAE_GAN_CELEBA.py\" -train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyN3WakOVhgO","colab_type":"text"},"source":["```\n","2020-08-01 16:43:02.984443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-08-01 16:43:04.421438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","epoch: 1 kl_loss: 2.962141526767186 rec_loss: 33964.165736607145 gen_loss: 1.321405144418989 dis_loss: 2.0456856284822735\n","epoch: 2 kl_loss: 5.137752359935216 rec_loss: 33965.15645089286 gen_loss: 1.3291666037695749 dis_loss: 1.967145458630153\n","epoch: 3 kl_loss: 9.7994768006461 rec_loss: 33988.03064732143 gen_loss: 1.329431552886963 dis_loss: 1.910723556791033\n","epoch: 4 kl_loss: 14.090135830470494 rec_loss: 33968.15720982143 gen_loss: 1.32584230695452 dis_loss: 1.93308477469853\n","epoch: 5 kl_loss: 13.171565497262137 rec_loss: 33954.911830357145 gen_loss: 1.327327617917742 dis_loss: 1.9124574967793055\n","epoch: 6 kl_loss: 11.700706105913435 rec_loss: 33957.873058035715 gen_loss: 1.3302313034875053 dis_loss: 1.893787820679801\n","epoch: 7 kl_loss: 11.583125147138324 rec_loss: 33964.45977678571 gen_loss: 1.337658529281616 dis_loss: 1.8615181303024293\n","epoch: 8 kl_loss: 12.042632598876953 rec_loss: 33974.313549107144 gen_loss: 1.3465956435884747 dis_loss: 1.83523054259164\n","epoch: 9 kl_loss: 13.109707636151995 rec_loss: 33985.99948660714 gen_loss: 1.3531361273356846 dis_loss: 1.8055176217215403\n","epoch: 10 kl_loss: 15.465423769269671 rec_loss: 34000.21180803572 gen_loss: 1.359796748161316 dis_loss: 1.7838535520008632\n","epoch: 11 kl_loss: 17.383036237444195 rec_loss: 34010.98457589286 gen_loss: 1.365008831705366 dis_loss: 1.7648505190440587\n","epoch: 12 kl_loss: 19.57232307434082 rec_loss: 34027.73841517857 gen_loss: 1.3692116403579713 dis_loss: 1.7510448973519461\n","epoch: 13 kl_loss: 21.685968191964285 rec_loss: 34043.186517857146 gen_loss: 1.3715003040858678 dis_loss: 1.742872221129281\n","epoch: 14 kl_loss: 23.7576331111363 rec_loss: 34054.21424107143 gen_loss: 1.3741033812931607 dis_loss: 1.7361047765186854\n","epoch: 15 kl_loss: 25.73105272565569 rec_loss: 34063.51828125 gen_loss: 1.3741602345875332 dis_loss: 1.7370231771469116\n","epoch: 16 kl_loss: 27.847841142926896 rec_loss: 34073.49229910714 gen_loss: 1.375896978378296 dis_loss: 1.7319439138684953\n","epoch: 17 kl_loss: 29.115926252092635 rec_loss: 34074.964419642856 gen_loss: 1.3763791043417795 dis_loss: 1.729866703578404\n","epoch: 18 kl_loss: 31.27298583984375 rec_loss: 34083.16 gen_loss: 1.3777046128681727 dis_loss: 1.7265419592176166\n","epoch: 19 kl_loss: 33.23052274431501 rec_loss: 34086.89506696429 gen_loss: 1.3780135318211146 dis_loss: 1.7256221791676112\n","epoch: 20 kl_loss: 35.0583896963937 rec_loss: 34092.30703125 gen_loss: 1.3779155104500906 dis_loss: 1.7246269157954626\n","epoch: 21 kl_loss: 37.574326019287106 rec_loss: 34102.43700892857 gen_loss: 1.3775848586218697 dis_loss: 1.7265074566432408\n","epoch: 22 kl_loss: 39.26558218819754 rec_loss: 34107.99169642857 gen_loss: 1.3784861060551235 dis_loss: 1.7228935888835362\n","epoch: 23 kl_loss: 41.677415182931085 rec_loss: 34119.91044642857 gen_loss: 1.379320161683219 dis_loss: 1.7209103216443744\n","epoch: 24 kl_loss: 43.63315054757255 rec_loss: 34128.848392857144 gen_loss: 1.3792558465685163 dis_loss: 1.721278817313058\n","epoch: 25 kl_loss: 45.33409138270787 rec_loss: 34137.019977678574 gen_loss: 1.3795912735802787 dis_loss: 1.7192173433303832\n","epoch: 26 kl_loss: 47.45547221592494 rec_loss: 34149.37857142857 gen_loss: 1.3805492653165545 dis_loss: 1.7168120118549892\n","epoch: 27 kl_loss: 49.487347085135326 rec_loss: 34161.41821428572 gen_loss: 1.381143136705671 dis_loss: 1.7157629455838885\n","epoch: 28 kl_loss: 51.46339407784598 rec_loss: 34172.49696428572 gen_loss: 1.3816830675942557 dis_loss: 1.7137122869491577\n","epoch: 29 kl_loss: 53.98505102975028 rec_loss: 34187.58897321428 gen_loss: 1.3815480525153023 dis_loss: 1.7138964094434466\n","epoch: 30 kl_loss: 55.79277108328683 rec_loss: 34196.93537946429 gen_loss: 1.3817425850459508 dis_loss: 1.7134032712663922\n","epoch: 31 kl_loss: 57.92976601736886 rec_loss: 34211.78301339286 gen_loss: 1.3822022369929723 dis_loss: 1.7118973588943482\n","epoch: 32 kl_loss: 59.62549924577986 rec_loss: 34220.79745535714 gen_loss: 1.3822157321657453 dis_loss: 1.7118654237474713\n","epoch: 33 kl_loss: 61.15174948556083 rec_loss: 34230.38841517857 gen_loss: 1.382819471359253 dis_loss: 1.7097381033216204\n","epoch: 34 kl_loss: 62.812105407714846 rec_loss: 34240.29245535714 gen_loss: 1.3827474396569388 dis_loss: 1.710131196975708\n","epoch: 35 kl_loss: 64.57016996111189 rec_loss: 34251.79991071428 gen_loss: 1.3830843196596418 dis_loss: 1.7092374317986625\n","epoch: 36 kl_loss: 66.09705139160157 rec_loss: 34262.190959821426 gen_loss: 1.3826869433266775 dis_loss: 1.7097733184269497\n","epoch: 37 kl_loss: 67.46325147356306 rec_loss: 34270.479419642856 gen_loss: 1.383232113974435 dis_loss: 1.708902929850987\n","epoch: 38 kl_loss: 68.90778281075613 rec_loss: 34279.02700892857 gen_loss: 1.383060075214931 dis_loss: 1.7096641308920724\n","epoch: 39 kl_loss: 69.52348813738142 rec_loss: 34282.432589285716 gen_loss: 1.3833673776899065 dis_loss: 1.7082323476246426\n","epoch: 40 kl_loss: 70.24256696428571 rec_loss: 34285.84040178572 gen_loss: 1.3833477871758597 dis_loss: 1.7084911591666085\n","epoch: 41 kl_loss: 70.64541019984654 rec_loss: 34288.833325892854 gen_loss: 1.3832785184042795 dis_loss: 1.7083639866965157\n","epoch: 42 kl_loss: 72.31373508998325 rec_loss: 34305.973705357144 gen_loss: 1.3837467895235334 dis_loss: 1.707347217287336\n","epoch: 43 kl_loss: 73.50221919468471 rec_loss: 34315.239330357144 gen_loss: 1.3838839026859828 dis_loss: 1.70675286088671\n","epoch: 44 kl_loss: 74.44625963483539 rec_loss: 34320.715625 gen_loss: 1.3837430218287876 dis_loss: 1.7071442488261632\n","epoch: 45 kl_loss: 74.66208435058594 rec_loss: 34319.05446428571 gen_loss: 1.383594615118844 dis_loss: 1.707358628000532\n","epoch: 46 kl_loss: 76.15031821114677 rec_loss: 34333.97720982143 gen_loss: 1.3838593687329974 dis_loss: 1.7068790687833513\n","epoch: 47 kl_loss: 76.57560141427176 rec_loss: 34335.275401785715 gen_loss: 1.3838876451764788 dis_loss: 1.7063000072751726\n","epoch: 48 kl_loss: 77.69873120989118 rec_loss: 34347.51225446429 gen_loss: 1.3839182887758528 dis_loss: 1.7066077879496984\n","epoch: 49 kl_loss: 78.32981039864676 rec_loss: 34350.208348214284 gen_loss: 1.3836617817197527 dis_loss: 1.7071284873144967\n","epoch: 50 kl_loss: 79.07099884033204 rec_loss: 34357.15212053571 gen_loss: 1.3838938324792045 dis_loss: 1.7065021678379604\n","epoch: 51 kl_loss: 80.10747013636998 rec_loss: 34365.381495535716 gen_loss: 1.3836813981192453 dis_loss: 1.7066746003287179\n","epoch: 52 kl_loss: 80.59990901402065 rec_loss: 34368.60267857143 gen_loss: 1.384287155015128 dis_loss: 1.705610692841666\n","epoch: 53 kl_loss: 80.71182852608817 rec_loss: 34367.98582589286 gen_loss: 1.3839487900052752 dis_loss: 1.7060070862088885\n","epoch: 54 kl_loss: 81.15965279715402 rec_loss: 34371.721629464286 gen_loss: 1.3840444019862583 dis_loss: 1.7061667714800153\n","epoch: 55 kl_loss: 81.12030434744699 rec_loss: 34370.43861607143 gen_loss: 1.3842100361415317 dis_loss: 1.705528143474034\n","epoch: 56 kl_loss: 81.44650333949498 rec_loss: 34371.23008928572 gen_loss: 1.3842081008638654 dis_loss: 1.7056132595879692\n","epoch: 57 kl_loss: 81.33591836111886 rec_loss: 34370.20359375 gen_loss: 1.3839670031411306 dis_loss: 1.706088537488665\n","epoch: 58 kl_loss: 82.8059392438616 rec_loss: 34383.626361607145 gen_loss: 1.3841356257029942 dis_loss: 1.7059842586517333\n","epoch: 59 kl_loss: 82.94120300292968 rec_loss: 34382.28042410714 gen_loss: 1.3842183971405029 dis_loss: 1.7055891023363385\n","epoch: 60 kl_loss: 83.33817500523159 rec_loss: 34385.26238839285 gen_loss: 1.3842068535940988 dis_loss: 1.7058733245304654\n","epoch: 61 kl_loss: 83.62464508056641 rec_loss: 34387.7121875 gen_loss: 1.3843548692975725 dis_loss: 1.7053365952628\n","epoch: 62 kl_loss: 83.45772944859095 rec_loss: 34384.16823660714 gen_loss: 1.3841506556102208 dis_loss: 1.70592410496303\n","epoch: 63 kl_loss: 83.5045756312779 rec_loss: 34381.00091517857 gen_loss: 1.3841375875473023 dis_loss: 1.7059243617738997\n","epoch: 64 kl_loss: 83.72398232596261 rec_loss: 34379.89459821428 gen_loss: 1.3842518404551916 dis_loss: 1.7050596461977277\n","epoch: 65 kl_loss: 84.3271080671038 rec_loss: 34383.08285714286 gen_loss: 1.384055096762521 dis_loss: 1.7056835944311959\n","epoch: 66 kl_loss: 84.1241200038365 rec_loss: 34376.241763392856 gen_loss: 1.38426468031747 dis_loss: 1.7056328575951711\n","epoch: 67 kl_loss: 84.39215249197824 rec_loss: 34378.78694196429 gen_loss: 1.3842672109603882 dis_loss: 1.705782527923584\n","epoch: 68 kl_loss: 84.77786080496652 rec_loss: 34381.28988839286 gen_loss: 1.3842887558255876 dis_loss: 1.7050714567729406\n","epoch: 69 kl_loss: 84.89426461356027 rec_loss: 34379.58703125 gen_loss: 1.3840333611624582 dis_loss: 1.7061873483657837\n","epoch: 70 kl_loss: 85.1562810407366 rec_loss: 34380.03848214286 gen_loss: 1.3841234350204468 dis_loss: 1.705816068649292\n","epoch: 71 kl_loss: 85.510706917899 rec_loss: 34379.607142857145 gen_loss: 1.3839653812135968 dis_loss: 1.7061383288247245\n","epoch: 72 kl_loss: 85.72175772530692 rec_loss: 34378.80225446429 gen_loss: 1.3838342503138952 dis_loss: 1.706092299733843\n","epoch: 73 kl_loss: 85.87711242675782 rec_loss: 34377.72301339286 gen_loss: 1.3840227440425328 dis_loss: 1.7062056003298078\n","epoch: 74 kl_loss: 85.99447187151227 rec_loss: 34374.348973214284 gen_loss: 1.3837871742248535 dis_loss: 1.7062095791952951\n","epoch: 75 kl_loss: 85.90949890136719 rec_loss: 34371.95167410714 gen_loss: 1.3840167692729406 dis_loss: 1.7061152614865984\n","epoch: 76 kl_loss: 85.82504010881696 rec_loss: 34364.720357142854 gen_loss: 1.3838128702981132 dis_loss: 1.7060585130964008\n","epoch: 77 kl_loss: 86.06388658796038 rec_loss: 34365.095089285714 gen_loss: 1.383832117489406 dis_loss: 1.7065978860855102\n","epoch: 78 kl_loss: 85.56693211146764 rec_loss: 34357.732388392855 gen_loss: 1.3839327117374964 dis_loss: 1.7065201241629464\n","epoch: 79 kl_loss: 86.10196568080357 rec_loss: 34361.72026785714 gen_loss: 1.3833737686702183 dis_loss: 1.707407442501613\n","epoch: 80 kl_loss: 86.04906406947545 rec_loss: 34360.06372767857 gen_loss: 1.3838147790091377 dis_loss: 1.7064842578342982\n","epoch: 81 kl_loss: 85.83075836181641 rec_loss: 34356.73075892857 gen_loss: 1.3837784664971489 dis_loss: 1.7068687786374774\n","epoch: 82 kl_loss: 86.04894247872488 rec_loss: 34358.47171875 gen_loss: 1.383905290876116 dis_loss: 1.7065698146820067\n","epoch: 83 kl_loss: 85.82742523193359 rec_loss: 34354.168660714284 gen_loss: 1.3836481162479946 dis_loss: 1.7070997606004987\n","epoch: 84 kl_loss: 86.14029122488839 rec_loss: 34355.90078125 gen_loss: 1.3839688464573452 dis_loss: 1.7066369642530168\n","epoch: 85 kl_loss: 85.92175907679966 rec_loss: 34352.076517857146 gen_loss: 1.3835384491511753 dis_loss: 1.7079682234355382\n","epoch: 86 kl_loss: 85.56305572509766 rec_loss: 34346.579754464285 gen_loss: 1.3835766233716693 dis_loss: 1.7068063654218402\n","epoch: 87 kl_loss: 85.92602469308035 rec_loss: 34348.40435267857 gen_loss: 1.3838867677961078 dis_loss: 1.7067021989822388\n","epoch: 88 kl_loss: 85.86845990862165 rec_loss: 34348.40087053571 gen_loss: 1.3833983775547574 dis_loss: 1.70750431401389\n","epoch: 89 kl_loss: 85.44602935791016 rec_loss: 34342.61477678571 gen_loss: 1.3834616558892385 dis_loss: 1.707607011113848\n","epoch: 90 kl_loss: 85.62804748535156 rec_loss: 34343.31861607143 gen_loss: 1.3836748354775565 dis_loss: 1.7065250955309186\n","epoch: 91 kl_loss: 86.09240975516182 rec_loss: 34347.82667410714 gen_loss: 1.3836062240600586 dis_loss: 1.7078418649945941\n","epoch: 92 kl_loss: 85.72449563162668 rec_loss: 34341.9471875 gen_loss: 1.3837433528900147 dis_loss: 1.706621764728001\n","epoch: 93 kl_loss: 85.76929081508092 rec_loss: 34342.04140625 gen_loss: 1.383413999421256 dis_loss: 1.7077268552780152\n","epoch: 94 kl_loss: 85.68255301339286 rec_loss: 34339.32098214285 gen_loss: 1.383709192957197 dis_loss: 1.706992895943778\n","epoch: 95 kl_loss: 85.50696759905134 rec_loss: 34335.96642857143 gen_loss: 1.383680443763733 dis_loss: 1.7068477698734827\n","epoch: 96 kl_loss: 85.07222834995815 rec_loss: 34330.88631696429 gen_loss: 1.3836120864323207 dis_loss: 1.7073457288742064\n","epoch: 97 kl_loss: 84.7581001499721 rec_loss: 34326.088214285715 gen_loss: 1.3834642703192574 dis_loss: 1.707805550439017\n","epoch: 98 kl_loss: 85.37989166259766 rec_loss: 34332.816875 gen_loss: 1.3836876242501395 dis_loss: 1.7071906314577374\n","epoch: 99 kl_loss: 85.13986053466797 rec_loss: 34329.64060267857 gen_loss: 1.3835193307059153 dis_loss: 1.7074520901271275\n","epoch: 100 kl_loss: 85.28985251290457 rec_loss: 34328.55883928572 gen_loss: 1.3836176824569701 dis_loss: 1.707086410522461\n","18:21:15\n","```"]},{"cell_type":"markdown","metadata":{"id":"oKJLZniwgRKT","colab_type":"text"},"source":["# Evaluation using IS, FID and PR"]},{"cell_type":"markdown","metadata":{"id":"_OQ_tjOcs3_-","colab_type":"text"},"source":["## MNIST classifier training"]},{"cell_type":"code","metadata":{"id":"Xb2XziEsgUsL","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/Evaluation/MnistClassifier.py\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7IHf8sGhzsr","colab_type":"text"},"source":["```\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 7s 115us/step - loss: 0.2175 - accuracy: 0.9328 - val_loss: 0.0602 - val_accuracy: 0.9817\n","Epoch 2/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0622 - accuracy: 0.9805 - val_loss: 0.0362 - val_accuracy: 0.9866\n","Epoch 3/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.0265 - val_accuracy: 0.9903\n","Epoch 4/20\n","60000/60000 [==============================] - 5s 76us/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 0.0327 - val_accuracy: 0.9884\n","Epoch 5/20\n","60000/60000 [==============================] - 5s 76us/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0323 - val_accuracy: 0.9893\n","Epoch 6/20\n","60000/60000 [==============================] - 5s 76us/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0265 - val_accuracy: 0.9913\n","Epoch 7/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0282 - val_accuracy: 0.9907\n","Epoch 8/20\n","60000/60000 [==============================] - 5s 75us/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0257 - val_accuracy: 0.9918\n","Epoch 9/20\n","60000/60000 [==============================] - 5s 75us/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0265 - val_accuracy: 0.9911\n","Epoch 10/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0297 - val_accuracy: 0.9915\n","Epoch 11/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0272 - val_accuracy: 0.9914\n","Epoch 12/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0297 - val_accuracy: 0.9916\n","Epoch 13/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0309 - val_accuracy: 0.9914\n","Epoch 14/20\n","60000/60000 [==============================] - 4s 74us/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0291 - val_accuracy: 0.9911\n","Epoch 15/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0313 - val_accuracy: 0.9916\n","Epoch 16/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.0308 - val_accuracy: 0.9911\n","Epoch 17/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0325 - val_accuracy: 0.9913\n","Epoch 18/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0318 - val_accuracy: 0.9913\n","Epoch 19/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0311 - val_accuracy: 0.9913\n","Epoch 20/20\n","60000/60000 [==============================] - 4s 75us/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0337 - val_accuracy: 0.9910\n","Test loss: 0.033691493619382104\n","Test accuracy: 0.9909999966621399\n","```"]},{"cell_type":"markdown","metadata":{"id":"tFsujKojs75A","colab_type":"text"},"source":["## IS, FID and PR results"]},{"cell_type":"markdown","metadata":{"id":"1Nk8AWtD2zWD","colab_type":"text"},"source":["### Inception Score"]},{"cell_type":"code","metadata":{"id":"v5eAbdKmtQES","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/Evaluation/InceptionScore.py\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IzlYCCM71Scd","colab_type":"text"},"source":["\n","\n","```\n","Inception Score for mnistReal folder is mu: 7.248465061187744, sigma: 1.2578366994857788\n","Inception Score for mnistGAN folder is mu: 6.801172733306885, sigma: 0.7616515159606934\n","Inception Score for mnistVAE folder is mu: 6.20330810546875, sigma: 0.651694118976593\n","Inception Score for mnistVAEGAN folder is mu: 6.07790470123291, sigma: 0.7310859560966492\n","\n","Inception Score for celebaReal folder is mu: 2.4536776542663574, sigma: 0.4387388229370117\n","Inception Score for celebaGAN folder is mu: 2.12199068069458, sigma: 0.2311292141675949\n","Inception Score for celebaVAE folder is mu: 1.7562503814697266, sigma: 0.1496589630842209\n","Inception Score for celebaVAEGAN folder is mu: 1.833031415939331, sigma: 0.2291153222322464\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d3XI1YTt22z_","colab_type":"text"},"source":["### Fetchet Inception Distance"]},{"cell_type":"code","metadata":{"id":"n1hNvVnptP02","colab_type":"code","colab":{}},"source":["!python3 \"/content/drive/My Drive/Thesis/Sources/Evaluation/FrechetInceptionDistance.py\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZu1lBAa11SO","colab_type":"text"},"source":["\n","\n","```\n","FID Score for mnistGAN folder is: 141.068\n","FID Score for mnistVAE folder is: 204.588\n","FID Score for mnistVAEGAN folder is: 175.813\n","\n","FID Score for celebaGAN folder is: 95.995\n","FID Score for celebaVAE folder is: 114.133\n","FID Score for celebaVAEGAN folder is: 143.035\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J42kbaUj26um","colab_type":"text"},"source":["### Precision and Recall"]},{"cell_type":"markdown","metadata":{"id":"zclN279H29iW","colab_type":"text"},"source":["Command to execute in terminal (note: requires TensorFlow 1.14)\n","\n","```\n","python PrecisionRecallPack/prd_from_image_folders.py --inception_path ./inception.pb --reference_dir ./mnistReal/ --eval_dirs ./mnistGAN ./mnistVAE ./mnistVAEGAN --eval_labels GAN VAE VAEGAN\n","python PrecisionRecallPack/prd_from_image_folders.py --inception_path ./inception.pb --reference_dir ./celebaReal/ --eval_dirs ./celebaGAN ./celebaVAE ./celebaVAEGAN --eval_labels GAN VAE VAEGAN\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xlzx4sPU3Spw","colab_type":"text"},"source":["#### MNIST\n","\n","```\n","computing inception embeddings for mnistReal\n","computing inception embeddings for mnistGAN\n","computing PRD\n","computing inception embeddings for mnistVAE\n","computing PRD\n","computing inception embeddings for mnistVAEGAN\n","computing PRD\n","plotting results\n","\n","F_8   F_1/8     model\n","0.920 0.915     mnistGAN\n","0.827 0.859     mnistVAE\n","0.857 0.904     mnistVAEGAN\n","```"]},{"cell_type":"markdown","metadata":{"id":"1xs_k-WN3SfY","colab_type":"text"},"source":["#### CELEBA\n","```\n","computing inception embeddings for celebaReal\n","computing inception embeddings for celebaGAN\n","computing PRD\n","computing inception embeddings for celebaVAE\n","computing PRD\n","computing inception embeddings for celebaVAEGAN\n","computing PRD\n","plotting results\n","\n","F_8   F_1/8     model\n","0.394 0.593     celebaGAN\n","0.102 0.377     celebaVAE\n","0.138 0.395     celebaVAEGAN\n","```\n"]}]}